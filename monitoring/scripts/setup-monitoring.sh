#!/bin/bash

# HankookTire SmartSensor 2.0 - ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
# ì°¨ì„¸ëŒ€ í†µí•© ìŠ¤ë§ˆíŠ¸ íƒ€ì´ì–´ ì„¼ì„œ ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ êµ¬ì¶•

set -euo pipefail

# ìƒ‰ìƒ ì •ì˜
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[0;33m'
BLUE='\033[0;34m'
PURPLE='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# ë¡œê¹… í•¨ìˆ˜
log() {
    echo -e "${GREEN}[$(date +'%Y-%m-%d %H:%M:%S')] $1${NC}"
}

warn() {
    echo -e "${YELLOW}[$(date +'%Y-%m-%d %H:%M:%S')] WARNING: $1${NC}"
}

error() {
    echo -e "${RED}[$(date +'%Y-%m-%d %H:%M:%S')] ERROR: $1${NC}"
}

info() {
    echo -e "${BLUE}[$(date +'%Y-%m-%d %H:%M:%S')] INFO: $1${NC}"
}

# ìŠ¤í¬ë¦½íŠ¸ ì‹œì‘
log "ğŸš€ HankookTire SmartSensor 2.0 ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì„¤ì • ì‹œì‘"

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
NAMESPACE=${NAMESPACE:-"hankook-smartsensor"}
MONITORING_NAMESPACE=${MONITORING_NAMESPACE:-"monitoring"}
CLUSTER_NAME=${CLUSTER_NAME:-"hankook-production"}

# ì‚¬ì „ ìš”êµ¬ì‚¬í•­ í™•ì¸
check_prerequisites() {
    log "ğŸ“‹ ì‚¬ì „ ìš”êµ¬ì‚¬í•­ í™•ì¸ ì¤‘..."
    
    # kubectl ì„¤ì¹˜ í™•ì¸
    if ! command -v kubectl &> /dev/null; then
        error "kubectlì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."
        exit 1
    fi
    
    # í´ëŸ¬ìŠ¤í„° ì—°ê²° í™•ì¸
    if ! kubectl cluster-info &> /dev/null; then
        error "Kubernetes í´ëŸ¬ìŠ¤í„°ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        exit 1
    fi
    
    # Helm ì„¤ì¹˜ í™•ì¸ (ì„ íƒì‚¬í•­)
    if command -v helm &> /dev/null; then
        info "âœ… Helm ë°œê²¬: $(helm version --short)"
        HELM_AVAILABLE=true
    else
        warn "Helmì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ì¼ë¶€ ê¸°ëŠ¥ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        HELM_AVAILABLE=false
    fi
    
    log "âœ… ì‚¬ì „ ìš”êµ¬ì‚¬í•­ í™•ì¸ ì™„ë£Œ"
}

# ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±
create_namespaces() {
    log "ğŸ“ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„± ì¤‘..."
    
    # ëª¨ë‹ˆí„°ë§ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„±
    kubectl create namespace $MONITORING_NAMESPACE --dry-run=client -o yaml | kubectl apply -f -
    
    # ë ˆì´ë¸” ì¶”ê°€
    kubectl label namespace $MONITORING_NAMESPACE monitoring=enabled --overwrite
    kubectl label namespace $NAMESPACE monitoring=enabled --overwrite
    
    log "âœ… ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒì„± ì™„ë£Œ"
}

# Prometheus Operator ì„¤ì¹˜ (Helm ì‚¬ìš© ì‹œ)
install_prometheus_operator() {
    if [ "$HELM_AVAILABLE" = true ]; then
        log "ğŸ“Š Prometheus Operator ì„¤ì¹˜ ì¤‘..."
        
        # Prometheus Community Helm ì €ì¥ì†Œ ì¶”ê°€
        helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
        helm repo update
        
        # kube-prometheus-stack ì„¤ì¹˜
        helm upgrade --install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
            --namespace $MONITORING_NAMESPACE \
            --create-namespace \
            --set prometheus.prometheusSpec.serviceMonitorSelectorNilUsesHelmValues=false \
            --set prometheus.prometheusSpec.podMonitorSelectorNilUsesHelmValues=false \
            --set prometheus.prometheusSpec.ruleSelectorNilUsesHelmValues=false \
            --set prometheus.prometheusSpec.retention=15d \
            --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.accessModes[0]=ReadWriteOnce \
            --set prometheus.prometheusSpec.storageSpec.volumeClaimTemplate.spec.resources.requests.storage=50Gi \
            --set alertmanager.alertmanagerSpec.storage.volumeClaimTemplate.spec.accessModes[0]=ReadWriteOnce \
            --set alertmanager.alertmanagerSpec.storage.volumeClaimTemplate.spec.resources.requests.storage=5Gi \
            --set grafana.persistence.enabled=true \
            --set grafana.persistence.size=10Gi \
            --set grafana.adminPassword=admin123! \
            --wait
            
        log "âœ… Prometheus Operator ì„¤ì¹˜ ì™„ë£Œ"
    else
        warn "Helmì´ ì—†ì–´ Prometheus Operatorë¥¼ ê±´ë„ˆëœë‹ˆë‹¤."
    fi
}

# ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ë°°í¬
deploy_monitoring_stack() {
    log "ğŸ“ˆ ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ë°°í¬ ì¤‘..."
    
    # AlertManager ë°°í¬
    log "ğŸš¨ AlertManager ë°°í¬ ì¤‘..."
    kubectl apply -f ../kubernetes/alertmanager-deployment.yaml
    
    # ELK Stack ë°°í¬
    log "ğŸ“ ELK Stack ë°°í¬ ì¤‘..."
    kubectl apply -f ../kubernetes/elk-stack.yaml
    
    # ëª¨ë‹ˆí„°ë§ ìŠ¤íƒì´ ì´ë¯¸ ìˆë‹¤ë©´ ì¶”ê°€ë¡œ ë°°í¬
    if ! helm list -n $MONITORING_NAMESPACE | grep -q kube-prometheus-stack; then
        log "ğŸ“Š ê¸°ë³¸ ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ë°°í¬ ì¤‘..."
        kubectl apply -f ../kubernetes/monitoring-stack.yaml
    fi
    
    log "âœ… ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ë°°í¬ ì™„ë£Œ"
}

# Grafana ëŒ€ì‹œë³´ë“œ ì„¤ì •
setup_grafana_dashboards() {
    log "ğŸ“Š Grafana ëŒ€ì‹œë³´ë“œ ì„¤ì • ì¤‘..."
    
    # Grafana Pod ëŒ€ê¸°
    kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=grafana -n $MONITORING_NAMESPACE --timeout=300s
    
    # ëŒ€ì‹œë³´ë“œ ConfigMap ìƒì„±
    kubectl create configmap grafana-dashboards \
        --from-file=../grafana/dashboards/ \
        -n $MONITORING_NAMESPACE \
        --dry-run=client -o yaml | kubectl apply -f -
    
    # Provisioning ì„¤ì •
    kubectl create configmap grafana-provisioning \
        --from-file=../grafana/provisioning/ \
        -n $MONITORING_NAMESPACE \
        --dry-run=client -o yaml | kubectl apply -f -
    
    # Grafana ì¬ì‹œì‘í•˜ì—¬ ì„¤ì • ì ìš©
    kubectl rollout restart deployment/grafana -n $MONITORING_NAMESPACE || \
    kubectl rollout restart deployment/kube-prometheus-stack-grafana -n $MONITORING_NAMESPACE
    
    log "âœ… Grafana ëŒ€ì‹œë³´ë“œ ì„¤ì • ì™„ë£Œ"
}

# Prometheus ê·œì¹™ ì„¤ì •
setup_prometheus_rules() {
    log "ğŸ“ Prometheus ì•Œë¦¼ ê·œì¹™ ì„¤ì • ì¤‘..."
    
    # ì•Œë¦¼ ê·œì¹™ ConfigMap ìƒì„±
    kubectl create configmap hankook-alert-rules \
        --from-file=../prometheus/alert-rules/ \
        -n $MONITORING_NAMESPACE \
        --dry-run=client -o yaml | kubectl apply -f -
    
    # PrometheusRule CRD ìƒì„± (Operator ì‚¬ìš© ì‹œ)
    if kubectl get crd prometheusrules.monitoring.coreos.com &> /dev/null; then
        cat <<EOF | kubectl apply -f -
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: hankook-smartsensor-rules
  namespace: $MONITORING_NAMESPACE
  labels:
    app: hankook-smartsensor
    prometheus: kube-prometheus
    role: alert-rules
spec:
$(cat ../prometheus/alert-rules/hankook-sensor-alerts.yml | sed 's/^/  /')
EOF
    fi
    
    log "âœ… Prometheus ì•Œë¦¼ ê·œì¹™ ì„¤ì • ì™„ë£Œ"
}

# ServiceMonitor ìƒì„± (Prometheus Operator ì‚¬ìš© ì‹œ)
create_service_monitors() {
    if kubectl get crd servicemonitors.monitoring.coreos.com &> /dev/null; then
        log "ğŸ” ServiceMonitor ìƒì„± ì¤‘..."
        
        # HankookTire API ServiceMonitor
        cat <<EOF | kubectl apply -f -
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: hankook-api-monitor
  namespace: $MONITORING_NAMESPACE
  labels:
    app: hankook-smartsensor
spec:
  selector:
    matchLabels:
      app: hankook-api
  namespaceSelector:
    matchNames:
    - $NAMESPACE
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
EOF

        # PostgreSQL ServiceMonitor
        cat <<EOF | kubectl apply -f -
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: postgres-monitor
  namespace: $MONITORING_NAMESPACE
  labels:
    app: hankook-smartsensor
spec:
  selector:
    matchLabels:
      app: postgres
  namespaceSelector:
    matchNames:
    - $NAMESPACE
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
EOF

        # Redis ServiceMonitor
        cat <<EOF | kubectl apply -f -
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: redis-monitor
  namespace: $MONITORING_NAMESPACE
  labels:
    app: hankook-smartsensor
spec:
  selector:
    matchLabels:
      app: redis
  namespaceSelector:
    matchNames:
    - $NAMESPACE
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
EOF

        # MQTT ServiceMonitor
        cat <<EOF | kubectl apply -f -
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: mosquitto-monitor
  namespace: $MONITORING_NAMESPACE
  labels:
    app: hankook-smartsensor
spec:
  selector:
    matchLabels:
      app: mosquitto
  namespaceSelector:
    matchNames:
    - $NAMESPACE
  endpoints:
  - port: metrics
    interval: 30s
    path: /metrics
EOF

        log "âœ… ServiceMonitor ìƒì„± ì™„ë£Œ"
    else
        warn "Prometheus Operatorê°€ ì—†ì–´ ServiceMonitorë¥¼ ê±´ë„ˆëœë‹ˆë‹¤."
    fi
}

# í—¬ìŠ¤ì²´í¬ ìŠ¤í¬ë¦½íŠ¸ ë°°í¬
deploy_health_check() {
    log "ğŸ¥ í—¬ìŠ¤ì²´í¬ ìŠ¤í¬ë¦½íŠ¸ ë°°í¬ ì¤‘..."
    
    # í—¬ìŠ¤ì²´í¬ ConfigMap ìƒì„±
    kubectl create configmap health-check-script \
        --from-file=health-check.py \
        -n $NAMESPACE \
        --dry-run=client -o yaml | kubectl apply -f -
    
    # í—¬ìŠ¤ì²´í¬ CronJob ìƒì„±
    cat <<EOF | kubectl apply -f -
apiVersion: batch/v1
kind: CronJob
metadata:
  name: health-check
  namespace: $NAMESPACE
  labels:
    app: hankook-smartsensor
    component: monitoring
spec:
  schedule: "*/5 * * * *"  # 5ë¶„ë§ˆë‹¤ ì‹¤í–‰
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: health-check
            image: python:3.11-slim
            command:
            - /bin/bash
            - -c
            - |
              pip install asyncio aiohttp psycopg2-binary redis
              python /scripts/health-check.py
            env:
            - name: POSTGRES_HOST
              value: "postgres-service"
            - name: POSTGRES_USER
              value: "hankook"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: database-credentials
                  key: password
            - name: REDIS_HOST
              value: "redis-service"
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: redis-credentials
                  key: password
            - name: API_BASE_URL
              value: "http://api-service:8000"
            - name: SLACK_WEBHOOK_URL
              valueFrom:
                secretKeyRef:
                  name: alertmanager-secrets
                  key: slack-webhook
                  optional: true
            volumeMounts:
            - name: scripts
              mountPath: /scripts
            - name: logs
              mountPath: /var/log
          volumes:
          - name: scripts
            configMap:
              name: health-check-script
              defaultMode: 0755
          - name: logs
            emptyDir: {}
          restartPolicy: OnFailure
EOF

    log "âœ… í—¬ìŠ¤ì²´í¬ ìŠ¤í¬ë¦½íŠ¸ ë°°í¬ ì™„ë£Œ"
}

# ë¡œê·¸ ìˆ˜ì§‘ ì„¤ì •
setup_log_collection() {
    log "ğŸ“ ë¡œê·¸ ìˆ˜ì§‘ ì„¤ì • ì¤‘..."
    
    # Fluentd DaemonSet (Filebeat ëŒ€ì‹  ì‚¬ìš© ê°€ëŠ¥)
    if [ "${USE_FLUENTD:-false}" = "true" ]; then
        log "ğŸ”„ Fluentd ë¡œê·¸ ìˆ˜ì§‘ê¸° ì„¤ì • ì¤‘..."
        
        # Fluentd ConfigMap
        cat <<EOF | kubectl apply -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: fluentd-config
  namespace: $NAMESPACE
data:
  fluent.conf: |
    <source>
      @type tail
      path /var/log/containers/hankook-*.log
      pos_file /var/log/fluentd-containers.log.pos
      tag kubernetes.*
      format json
      read_from_head true
    </source>
    
    <filter kubernetes.**>
      @type kubernetes_metadata
    </filter>
    
    <match kubernetes.**>
      @type elasticsearch
      host elasticsearch-service
      port 9200
      logstash_format true
      logstash_prefix hankook-smartsensor
    </match>
EOF

        # Fluentd DaemonSet
        cat <<EOF | kubectl apply -f -
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
  namespace: $NAMESPACE
spec:
  selector:
    matchLabels:
      app: fluentd
  template:
    metadata:
      labels:
        app: fluentd
    spec:
      containers:
      - name: fluentd
        image: fluent/fluentd-kubernetes-daemonset:v1-debian-elasticsearch
        env:
        - name: FLUENT_ELASTICSEARCH_HOST
          value: "elasticsearch-service"
        - name: FLUENT_ELASTICSEARCH_PORT
          value: "9200"
        volumeMounts:
        - name: varlog
          mountPath: /var/log
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
        - name: config
          mountPath: /fluentd/etc/fluent.conf
          subPath: fluent.conf
      volumes:
      - name: varlog
        hostPath:
          path: /var/log
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
      - name: config
        configMap:
          name: fluentd-config
EOF
    fi
    
    log "âœ… ë¡œê·¸ ìˆ˜ì§‘ ì„¤ì • ì™„ë£Œ"
}

# ë„¤íŠ¸ì›Œí¬ ì •ì±… ì„¤ì •
setup_network_policies() {
    log "ğŸ”’ ë„¤íŠ¸ì›Œí¬ ì •ì±… ì„¤ì • ì¤‘..."
    
    # ëª¨ë‹ˆí„°ë§ ë„¤íŠ¸ì›Œí¬ ì •ì±…
    cat <<EOF | kubectl apply -f -
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: monitoring-network-policy
  namespace: $MONITORING_NAMESPACE
spec:
  podSelector: {}
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          name: $NAMESPACE
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
  - ports:
    - protocol: TCP
      port: 9090  # Prometheus
    - protocol: TCP
      port: 3000  # Grafana
    - protocol: TCP
      port: 9093  # AlertManager
  egress:
  - {} # ëª¨ë“  ì™¸ë¶€ ì—°ê²° í—ˆìš© (DNS, ì™¸ë¶€ ì•Œë¦¼ ë“±)
EOF

    log "âœ… ë„¤íŠ¸ì›Œí¬ ì •ì±… ì„¤ì • ì™„ë£Œ"
}

# Ingress ì„¤ì • ì—…ë°ì´íŠ¸
update_ingress() {
    log "ğŸŒ Ingress ì„¤ì • ì—…ë°ì´íŠ¸ ì¤‘..."
    
    # ëª¨ë‹ˆí„°ë§ ë„ë©”ì¸ì„ ê¸°ì¡´ Ingressì— ì¶”ê°€
    kubectl patch ingress hankook-smartsensor-ingress -n $NAMESPACE --type='json' -p='[
      {
        "op": "add",
        "path": "/spec/rules/-",
        "value": {
          "host": "monitoring.hankook-smartsensor.com",
          "http": {
            "paths": [
              {
                "path": "/prometheus",
                "pathType": "Prefix",
                "backend": {
                  "service": {
                    "name": "prometheus-service",
                    "port": {
                      "number": 9090
                    }
                  }
                }
              },
              {
                "path": "/grafana",
                "pathType": "Prefix",
                "backend": {
                  "service": {
                    "name": "grafana-service",
                    "port": {
                      "number": 3000
                    }
                  }
                }
              },
              {
                "path": "/alertmanager",
                "pathType": "Prefix",
                "backend": {
                  "service": {
                    "name": "alertmanager-service",
                    "port": {
                      "number": 9093
                    }
                  }
                }
              },
              {
                "path": "/kibana",
                "pathType": "Prefix",
                "backend": {
                  "service": {
                    "name": "kibana-service",
                    "port": {
                      "number": 5601
                    }
                  }
                }
              }
            ]
          }
        }
      }
    ]' || warn "Ingress ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ - ìˆ˜ë™ìœ¼ë¡œ í™•ì¸í•˜ì„¸ìš”."
    
    log "âœ… Ingress ì„¤ì • ì—…ë°ì´íŠ¸ ì™„ë£Œ"
}

# ìƒíƒœ í™•ì¸
check_deployment_status() {
    log "âœ… ë°°í¬ ìƒíƒœ í™•ì¸ ì¤‘..."
    
    info "ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ìƒíƒœ:"
    kubectl get namespaces | grep -E "$NAMESPACE|$MONITORING_NAMESPACE"
    
    info "ëª¨ë‹ˆí„°ë§ Pod ìƒíƒœ:"
    kubectl get pods -n $MONITORING_NAMESPACE
    
    info "ì„œë¹„ìŠ¤ ìƒíƒœ:"
    kubectl get svc -n $MONITORING_NAMESPACE
    
    info "Ingress ìƒíƒœ:"
    kubectl get ingress -n $NAMESPACE
    
    # í¬íŠ¸í¬ì›Œë”© ì •ë³´ ì œê³µ
    echo ""
    info "ğŸŒ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì ‘ì† ì •ë³´:"
    echo "  Grafana:      kubectl port-forward -n $MONITORING_NAMESPACE svc/grafana-service 3000:3000"
    echo "               ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:3000 ì ‘ì† (admin/admin123!)"
    echo ""
    echo "  Prometheus:   kubectl port-forward -n $MONITORING_NAMESPACE svc/prometheus-service 9090:9090"
    echo "               ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:9090 ì ‘ì†"
    echo ""
    echo "  AlertManager: kubectl port-forward -n $MONITORING_NAMESPACE svc/alertmanager-service 9093:9093"
    echo "               ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:9093 ì ‘ì†"
    echo ""
    echo "  Kibana:       kubectl port-forward -n $NAMESPACE svc/kibana-service 5601:5601"
    echo "               ë¸Œë¼ìš°ì €ì—ì„œ http://localhost:5601 ì ‘ì†"
}

# ì •ë¦¬ í•¨ìˆ˜
cleanup() {
    log "ğŸ§¹ ì •ë¦¬ ì‘ì—… ì¤‘..."
    # í•„ìš”ì‹œ ì •ë¦¬ ì‘ì—… ìˆ˜í–‰
}

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
main() {
    log "ğŸ¯ HankookTire SmartSensor 2.0 ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì„¤ì • ì‹œì‘"
    
    # ë‹¨ê³„ë³„ ì‹¤í–‰
    check_prerequisites
    create_namespaces
    install_prometheus_operator
    deploy_monitoring_stack
    setup_prometheus_rules
    create_service_monitors
    setup_grafana_dashboards
    deploy_health_check
    setup_log_collection
    setup_network_policies
    update_ingress
    
    # ë°°í¬ ì™„ë£Œ ëŒ€ê¸°
    log "â³ ì„œë¹„ìŠ¤ ì¤€ë¹„ ìƒíƒœ ëŒ€ê¸° ì¤‘..."
    kubectl wait --for=condition=ready pod -l app=prometheus -n $MONITORING_NAMESPACE --timeout=300s || warn "Prometheus ì¤€ë¹„ ì‹œê°„ ì´ˆê³¼"
    kubectl wait --for=condition=ready pod -l app.kubernetes.io/name=grafana -n $MONITORING_NAMESPACE --timeout=300s || warn "Grafana ì¤€ë¹„ ì‹œê°„ ì´ˆê³¼"
    
    check_deployment_status
    
    log "ğŸ‰ HankookTire SmartSensor 2.0 ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì„¤ì • ì™„ë£Œ!"
    
    # ì„±ê³µ ë©”ì‹œì§€
    echo ""
    echo "======================================================="
    echo "ğŸš€ HankookTire SmartSensor 2.0 ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!"
    echo "======================================================="
    echo ""
    echo "ğŸ“Š Grafana Dashboard: https://monitoring.hankook-smartsensor.com/grafana"
    echo "ğŸ“ˆ Prometheus Metrics: https://monitoring.hankook-smartsensor.com/prometheus"
    echo "ğŸš¨ AlertManager: https://monitoring.hankook-smartsensor.com/alertmanager"
    echo "ğŸ“ Kibana Logs: https://monitoring.hankook-smartsensor.com/kibana"
    echo ""
    echo "ğŸ” ê¸°ë³¸ ë¡œê·¸ì¸ ì •ë³´:"
    echo "  Grafana: admin / admin123!"
    echo ""
    echo "âš¡ ë‹¤ìŒ ë‹¨ê³„:"
    echo "  1. Grafanaì—ì„œ ë°ì´í„°ì†ŒìŠ¤ í™•ì¸"
    echo "  2. ëŒ€ì‹œë³´ë“œ ì»¤ìŠ¤í„°ë§ˆì´ì§•"
    echo "  3. ì•Œë¦¼ ì±„ë„ ì„¤ì • (Slack, Email)"
    echo "  4. ë°±ì—… ë° ë³´ì•ˆ ì„¤ì •"
    echo ""
}

# ì—ëŸ¬ ì²˜ë¦¬
trap cleanup EXIT
trap 'error "ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"; exit 1' ERR

# ë©”ì¸ í•¨ìˆ˜ ì‹¤í–‰
main "$@"