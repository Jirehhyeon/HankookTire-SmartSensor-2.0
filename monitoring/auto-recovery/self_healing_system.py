#!/usr/bin/env python3
"""
HankookTire SmartSensor 2.0 - Self-Healing & Auto-Recovery System
ì°¨ì„¸ëŒ€ ìê°€ ì¹˜ìœ  ë° ìë™ ë³µêµ¬ ì‹œìŠ¤í…œ

Advanced self-healing capabilities:
- Automatic service restart and recovery
- Smart load balancing and failover
- Predictive scaling based on ML models
- Auto-remediation of common issues
- Chaos engineering for resilience testing
"""

import asyncio
import logging
import json
import os
import time
import yaml
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Callable
from dataclasses import dataclass, asdict
from enum import Enum
import subprocess
import threading
from concurrent.futures import ThreadPoolExecutor
import psutil

# Kubernetes and Infrastructure
from kubernetes import client, config, watch
from kubernetes.client.rest import ApiException
import docker
import redis
import psycopg2
from psycopg2.extras import RealDictCursor

# Monitoring and Metrics
import aiohttp
import prometheus_client
from prometheus_client import Counter, Histogram, Gauge, CollectorRegistry

# ML for Predictive Actions
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
import joblib

# Configuration
KUBERNETES_NAMESPACE = os.getenv('KUBERNETES_NAMESPACE', 'hankook-smartsensor')
MONITORING_NAMESPACE = os.getenv('MONITORING_NAMESPACE', 'monitoring')
REDIS_HOST = os.getenv('REDIS_HOST', 'redis-service')
REDIS_PORT = int(os.getenv('REDIS_PORT', '6379'))
POSTGRES_HOST = os.getenv('POSTGRES_HOST', 'postgres-service')
API_BASE_URL = os.getenv('API_BASE_URL', 'http://api-service:8000')
SLACK_WEBHOOK = os.getenv('SLACK_WEBHOOK', '')
ENABLE_CHAOS_ENGINEERING = os.getenv('ENABLE_CHAOS_ENGINEERING', 'false').lower() == 'true'

# Logging Setup
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/var/log/self-healing.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Prometheus Metrics
registry = CollectorRegistry()
recovery_actions_total = Counter('self_healing_recovery_actions_total', 
                                'Total number of recovery actions taken', 
                                ['action_type', 'target_service'], registry=registry)
recovery_success_rate = Gauge('self_healing_success_rate', 
                             'Success rate of recovery actions', 
                             ['action_type'], registry=registry)
system_health_score = Gauge('self_healing_system_health_score', 
                           'Overall system health score', registry=registry)
prediction_accuracy = Gauge('self_healing_prediction_accuracy', 
                           'Accuracy of predictive scaling models', registry=registry)

class RecoveryAction(Enum):
    """ë³µêµ¬ ì•¡ì…˜ ìœ í˜•"""
    RESTART_POD = "restart_pod"
    SCALE_UP = "scale_up"
    SCALE_DOWN = "scale_down"
    RESTART_SERVICE = "restart_service"
    CLEAR_CACHE = "clear_cache"
    ROTATE_LOGS = "rotate_logs"
    UPDATE_CONFIG = "update_config"
    FAILOVER = "failover"
    CIRCUIT_BREAKER = "circuit_breaker"
    CLEANUP_RESOURCES = "cleanup_resources"
    REBALANCE_LOAD = "rebalance_load"
    CHAOS_TEST = "chaos_test"

class Severity(Enum):
    """ì‹¬ê°ë„"""
    INFO = 1
    WARNING = 2
    ERROR = 3
    CRITICAL = 4
    EMERGENCY = 5

@dataclass
class HealthIssue:
    """í—¬ìŠ¤ ì´ìŠˆ ì •ì˜"""
    component: str
    issue_type: str
    severity: Severity
    description: str
    metrics: Dict[str, Any]
    timestamp: datetime
    auto_recoverable: bool = True
    recovery_actions: List[RecoveryAction] = None
    cooldown_period: int = 300  # 5ë¶„

@dataclass
class RecoveryResult:
    """ë³µêµ¬ ê²°ê³¼"""
    action: RecoveryAction
    target: str
    success: bool
    duration: float
    message: str
    timestamp: datetime
    side_effects: List[str] = None

class SelfHealingSystem:
    """ìê°€ ì¹˜ìœ  ì‹œìŠ¤í…œ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.k8s_apps_v1 = None
        self.k8s_core_v1 = None
        self.docker_client = None
        self.redis_client = None
        self.session = None
        
        self.recovery_history = []
        self.action_cooldowns = {}
        self.health_checks = {}
        self.predictive_models = {}
        
        # ë³µêµ¬ ê·œì¹™ ì •ì˜
        self.recovery_rules = self._load_recovery_rules()
        
        # ìŠ¤ì¼€ì¼ë§ ì˜ˆì¸¡ ëª¨ë¸
        self.scaling_predictor = None
        self.scaling_scaler = StandardScaler()
        
        # ìƒíƒœ ì¶”ì 
        self.system_status = {
            'last_health_check': None,
            'active_issues': [],
            'recovery_queue': [],
            'circuit_breakers': {},
            'maintenance_mode': False
        }

    async def __aenter__(self):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì ì§„ì…"""
        # Kubernetes í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            config.load_incluster_config()
        except:
            config.load_kube_config()
        
        self.k8s_apps_v1 = client.AppsV1Api()
        self.k8s_core_v1 = client.CoreV1Api()
        
        # Docker í´ë¼ì´ì–¸íŠ¸ (ë¡œì»¬ ê°œë°œìš©)
        try:
            self.docker_client = docker.from_env()
        except:
            logger.warning("Docker í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ì‹¤íŒ¨")
        
        # Redis í´ë¼ì´ì–¸íŠ¸
        self.redis_client = redis.Redis(
            host=REDIS_HOST,
            port=REDIS_PORT,
            decode_responses=True
        )
        
        # HTTP ì„¸ì…˜
        timeout = aiohttp.ClientTimeout(total=30)
        self.session = aiohttp.ClientSession(timeout=timeout)
        
        # ì˜ˆì¸¡ ëª¨ë¸ ë¡œë“œ
        await self.load_predictive_models()
        
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """ë¹„ë™ê¸° ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ì ì¢…ë£Œ"""
        if self.session:
            await self.session.close()

    def _load_recovery_rules(self) -> Dict[str, Dict]:
        """ë³µêµ¬ ê·œì¹™ ë¡œë“œ"""
        return {
            # API ì„œë²„ ê´€ë ¨
            'api_high_response_time': {
                'condition': lambda metrics: metrics.get('avg_response_time', 0) > 2000,
                'actions': [RecoveryAction.SCALE_UP, RecoveryAction.RESTART_POD],
                'severity': Severity.WARNING,
                'cooldown': 300
            },
            'api_high_error_rate': {
                'condition': lambda metrics: metrics.get('error_rate', 0) > 0.05,
                'actions': [RecoveryAction.RESTART_POD, RecoveryAction.CLEAR_CACHE],
                'severity': Severity.ERROR,
                'cooldown': 180
            },
            'api_pod_crash_loop': {
                'condition': lambda metrics: metrics.get('restart_count', 0) > 5,
                'actions': [RecoveryAction.SCALE_UP, RecoveryAction.UPDATE_CONFIG],
                'severity': Severity.CRITICAL,
                'cooldown': 600
            },
            
            # ë°ì´í„°ë² ì´ìŠ¤ ê´€ë ¨
            'database_high_connections': {
                'condition': lambda metrics: metrics.get('active_connections', 0) > 180,
                'actions': [RecoveryAction.RESTART_SERVICE, RecoveryAction.CLEAR_CACHE],
                'severity': Severity.WARNING,
                'cooldown': 300
            },
            'database_deadlocks': {
                'condition': lambda metrics: metrics.get('deadlocks_per_minute', 0) > 5,
                'actions': [RecoveryAction.RESTART_SERVICE],
                'severity': Severity.ERROR,
                'cooldown': 600
            },
            'database_disk_space': {
                'condition': lambda metrics: metrics.get('disk_usage_percent', 0) > 85,
                'actions': [RecoveryAction.CLEANUP_RESOURCES, RecoveryAction.ROTATE_LOGS],
                'severity': Severity.CRITICAL,
                'cooldown': 900
            },
            
            # Redis ê´€ë ¨
            'redis_memory_high': {
                'condition': lambda metrics: metrics.get('memory_usage_percent', 0) > 90,
                'actions': [RecoveryAction.CLEAR_CACHE, RecoveryAction.RESTART_SERVICE],
                'severity': Severity.WARNING,
                'cooldown': 300
            },
            'redis_connection_spike': {
                'condition': lambda metrics: metrics.get('connected_clients', 0) > 1000,
                'actions': [RecoveryAction.CIRCUIT_BREAKER, RecoveryAction.REBALANCE_LOAD],
                'severity': Severity.ERROR,
                'cooldown': 180
            },
            
            # MQTT ê´€ë ¨
            'mqtt_connection_drop': {
                'condition': lambda metrics: metrics.get('client_disconnect_rate', 0) > 50,
                'actions': [RecoveryAction.RESTART_SERVICE, RecoveryAction.FAILOVER],
                'severity': Severity.ERROR,
                'cooldown': 300
            },
            
            # ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤
            'high_cpu_usage': {
                'condition': lambda metrics: metrics.get('cpu_usage_percent', 0) > 80,
                'actions': [RecoveryAction.SCALE_UP],
                'severity': Severity.WARNING,
                'cooldown': 600
            },
            'high_memory_usage': {
                'condition': lambda metrics: metrics.get('memory_usage_percent', 0) > 85,
                'actions': [RecoveryAction.CLEANUP_RESOURCES, RecoveryAction.SCALE_UP],
                'severity': Severity.WARNING,
                'cooldown': 600
            },
            'disk_space_critical': {
                'condition': lambda metrics: metrics.get('disk_usage_percent', 0) > 95,
                'actions': [RecoveryAction.CLEANUP_RESOURCES, RecoveryAction.ROTATE_LOGS],
                'severity': Severity.CRITICAL,
                'cooldown': 300
            }
        }

    async def continuous_health_monitoring(self):
        """ì§€ì†ì ì¸ í—¬ìŠ¤ ëª¨ë‹ˆí„°ë§"""
        logger.info("ğŸ¥ ìê°€ ì¹˜ìœ  ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ì‹œì‘...")
        
        while True:
            try:
                start_time = time.time()
                
                # í—¬ìŠ¤ ì²´í¬ ì‹¤í–‰
                health_issues = await self.perform_comprehensive_health_check()
                
                # ì´ìŠˆ ë¶„ì„ ë° ë³µêµ¬ ê³„íš
                recovery_plan = await self.analyze_and_plan_recovery(health_issues)
                
                # ë³µêµ¬ ì•¡ì…˜ ì‹¤í–‰
                if recovery_plan:
                    await self.execute_recovery_plan(recovery_plan)
                
                # ì˜ˆì¸¡ì  ìŠ¤ì¼€ì¼ë§
                await self.predictive_scaling()
                
                # ì‹œìŠ¤í…œ ìƒíƒœ ì—…ë°ì´íŠ¸
                await self.update_system_status(health_issues)
                
                # ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
                self.update_prometheus_metrics()
                
                # ì¹´ì˜¤ìŠ¤ ì—”ì§€ë‹ˆì–´ë§ (í™œì„±í™”ëœ ê²½ìš°)
                if ENABLE_CHAOS_ENGINEERING and datetime.now().hour in [2, 14]:  # ìƒˆë²½ 2ì‹œ, ì˜¤í›„ 2ì‹œ
                    await self.chaos_engineering_test()
                
                # ì‹¤í–‰ ì‹œê°„ ë¡œê¹…
                duration = time.time() - start_time
                logger.debug(f"í—¬ìŠ¤ ëª¨ë‹ˆí„°ë§ ì‚¬ì´í´ ì™„ë£Œ: {duration:.2f}ì´ˆ")
                
                # ëŒ€ê¸° (30ì´ˆ ê°„ê²©)
                await asyncio.sleep(30)
                
            except Exception as e:
                logger.error(f"âŒ í—¬ìŠ¤ ëª¨ë‹ˆí„°ë§ ì˜¤ë¥˜: {str(e)}")
                await asyncio.sleep(60)  # ì˜¤ë¥˜ ì‹œ 1ë¶„ ëŒ€ê¸°

    async def perform_comprehensive_health_check(self) -> List[HealthIssue]:
        """í¬ê´„ì  í—¬ìŠ¤ ì²´í¬"""
        issues = []
        
        try:
            # ë™ì‹œì— ëª¨ë“  í—¬ìŠ¤ ì²´í¬ ì‹¤í–‰
            health_check_tasks = [
                self.check_api_health(),
                self.check_database_health(),
                self.check_redis_health(),
                self.check_mqtt_health(),
                self.check_kubernetes_pods(),
                self.check_system_resources(),
                self.check_sensor_connectivity()
            ]
            
            results = await asyncio.gather(*health_check_tasks, return_exceptions=True)
            
            # ê²°ê³¼ ì²˜ë¦¬
            for result in results:
                if isinstance(result, list):
                    issues.extend(result)
                elif isinstance(result, Exception):
                    logger.error(f"í—¬ìŠ¤ ì²´í¬ ì˜¤ë¥˜: {str(result)}")
            
            self.system_status['last_health_check'] = datetime.now()
            logger.debug(f"ğŸ” í—¬ìŠ¤ ì²´í¬ ì™„ë£Œ: {len(issues)}ê°œ ì´ìŠˆ ë°œê²¬")
            
        except Exception as e:
            logger.error(f"âŒ í¬ê´„ì  í—¬ìŠ¤ ì²´í¬ ì‹¤íŒ¨: {str(e)}")
        
        return issues

    async def check_api_health(self) -> List[HealthIssue]:
        """API ì„œë²„ í—¬ìŠ¤ ì²´í¬"""
        issues = []
        
        try:
            # API ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            async with self.session.get(f"{API_BASE_URL}/metrics") as response:
                if response.status == 200:
                    metrics_text = await response.text()
                    metrics = self.parse_prometheus_metrics(metrics_text)
                    
                    # ê·œì¹™ ê¸°ë°˜ ì´ìŠˆ íƒì§€
                    for rule_name, rule in self.recovery_rules.items():
                        if 'api' in rule_name and rule['condition'](metrics):
                            issues.append(HealthIssue(
                                component='api-server',
                                issue_type=rule_name,
                                severity=rule['severity'],
                                description=f"API ì„œë²„ ì´ìŠˆ ê°ì§€: {rule_name}",
                                metrics=metrics,
                                timestamp=datetime.now(),
                                recovery_actions=rule['actions'],
                                cooldown_period=rule['cooldown']
                            ))
                else:
                    issues.append(HealthIssue(
                        component='api-server',
                        issue_type='api_unreachable',
                        severity=Severity.CRITICAL,
                        description=f"API ì„œë²„ ì ‘ê·¼ ë¶ˆê°€ (HTTP {response.status})",
                        metrics={'status_code': response.status},
                        timestamp=datetime.now(),
                        recovery_actions=[RecoveryAction.RESTART_POD, RecoveryAction.FAILOVER]
                    ))
                    
        except Exception as e:
            issues.append(HealthIssue(
                component='api-server',
                issue_type='connection_error',
                severity=Severity.CRITICAL,
                description=f"API ì„œë²„ ì—°ê²° ì˜¤ë¥˜: {str(e)}",
                metrics={},
                timestamp=datetime.now(),
                recovery_actions=[RecoveryAction.RESTART_POD]
            ))
        
        return issues

    async def check_database_health(self) -> List[HealthIssue]:
        """ë°ì´í„°ë² ì´ìŠ¤ í—¬ìŠ¤ ì²´í¬"""
        issues = []
        
        try:
            conn = psycopg2.connect(
                host=POSTGRES_HOST,
                port=5432,
                database='hankook_sensors',
                user='hankook',
                password=os.getenv('POSTGRES_PASSWORD', 'password'),
                connect_timeout=10
            )
            
            with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                # í™œì„± ì—°ê²° ìˆ˜ í™•ì¸
                cursor.execute("SELECT count(*) as active_connections FROM pg_stat_activity")
                active_connections = cursor.fetchone()['active_connections']
                
                # ë°ë“œë½ í™•ì¸
                cursor.execute("""
                    SELECT count(*) as deadlocks 
                    FROM pg_stat_database 
                    WHERE datname = 'hankook_sensors'
                """)
                deadlocks = cursor.fetchone()['deadlocks']
                
                # ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ í™•ì¸
                cursor.execute("SELECT pg_size_pretty(pg_database_size('hankook_sensors')) as db_size")
                db_size = cursor.fetchone()['db_size']
                
                # ëŠë¦° ì¿¼ë¦¬ í™•ì¸
                cursor.execute("""
                    SELECT count(*) as slow_queries 
                    FROM pg_stat_statements 
                    WHERE mean_exec_time > 1000
                """)
                slow_queries = cursor.fetchone()['slow_queries'] if cursor.rowcount > 0 else 0
                
                metrics = {
                    'active_connections': active_connections,
                    'deadlocks_per_minute': deadlocks,
                    'slow_queries': slow_queries,
                    'disk_usage_percent': 70  # ì‹¤ì œë¡œëŠ” ì‹œìŠ¤í…œ ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ ì²´í¬
                }
                
                # ê·œì¹™ ê¸°ë°˜ ì´ìŠˆ íƒì§€
                for rule_name, rule in self.recovery_rules.items():
                    if 'database' in rule_name and rule['condition'](metrics):
                        issues.append(HealthIssue(
                            component='database',
                            issue_type=rule_name,
                            severity=rule['severity'],
                            description=f"ë°ì´í„°ë² ì´ìŠ¤ ì´ìŠˆ ê°ì§€: {rule_name}",
                            metrics=metrics,
                            timestamp=datetime.now(),
                            recovery_actions=rule['actions'],
                            cooldown_period=rule['cooldown']
                        ))
            
            conn.close()
            
        except Exception as e:
            issues.append(HealthIssue(
                component='database',
                issue_type='connection_error',
                severity=Severity.CRITICAL,
                description=f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {str(e)}",
                metrics={},
                timestamp=datetime.now(),
                recovery_actions=[RecoveryAction.RESTART_SERVICE]
            ))
        
        return issues

    async def check_redis_health(self) -> List[HealthIssue]:
        """Redis í—¬ìŠ¤ ì²´í¬"""
        issues = []
        
        try:
            # Redis ì •ë³´ ìˆ˜ì§‘
            info = self.redis_client.info()
            
            metrics = {
                'memory_usage_percent': (info['used_memory'] / info.get('maxmemory', info['used_memory'] * 2)) * 100,
                'connected_clients': info['connected_clients'],
                'keyspace_hits': info['keyspace_hits'],
                'keyspace_misses': info['keyspace_misses']
            }
            
            # ê·œì¹™ ê¸°ë°˜ ì´ìŠˆ íƒì§€
            for rule_name, rule in self.recovery_rules.items():
                if 'redis' in rule_name and rule['condition'](metrics):
                    issues.append(HealthIssue(
                        component='redis',
                        issue_type=rule_name,
                        severity=rule['severity'],
                        description=f"Redis ì´ìŠˆ ê°ì§€: {rule_name}",
                        metrics=metrics,
                        timestamp=datetime.now(),
                        recovery_actions=rule['actions'],
                        cooldown_period=rule['cooldown']
                    ))
                    
        except Exception as e:
            issues.append(HealthIssue(
                component='redis',
                issue_type='connection_error',
                severity=Severity.CRITICAL,
                description=f"Redis ì—°ê²° ì˜¤ë¥˜: {str(e)}",
                metrics={},
                timestamp=datetime.now(),
                recovery_actions=[RecoveryAction.RESTART_SERVICE]
            ))
        
        return issues

    async def check_mqtt_health(self) -> List[HealthIssue]:
        """MQTT ë¸Œë¡œì»¤ í—¬ìŠ¤ ì²´í¬"""
        issues = []
        
        try:
            # MQTT ë©”íŠ¸ë¦­ ìˆ˜ì§‘ (Prometheus exporter í†µí•´)
            async with self.session.get("http://mosquitto-service:9234/metrics") as response:
                if response.status == 200:
                    metrics_text = await response.text()
                    metrics = self.parse_prometheus_metrics(metrics_text, prefix='mosquitto_')
                    
                    # ê·œì¹™ ê¸°ë°˜ ì´ìŠˆ íƒì§€
                    for rule_name, rule in self.recovery_rules.items():
                        if 'mqtt' in rule_name and rule['condition'](metrics):
                            issues.append(HealthIssue(
                                component='mqtt',
                                issue_type=rule_name,
                                severity=rule['severity'],
                                description=f"MQTT ë¸Œë¡œì»¤ ì´ìŠˆ ê°ì§€: {rule_name}",
                                metrics=metrics,
                                timestamp=datetime.now(),
                                recovery_actions=rule['actions'],
                                cooldown_period=rule['cooldown']
                            ))
                            
        except Exception as e:
            issues.append(HealthIssue(
                component='mqtt',
                issue_type='metrics_error',
                severity=Severity.WARNING,
                description=f"MQTT ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì˜¤ë¥˜: {str(e)}",
                metrics={},
                timestamp=datetime.now(),
                recovery_actions=[RecoveryAction.RESTART_SERVICE]
            ))
        
        return issues

    async def check_kubernetes_pods(self) -> List[HealthIssue]:
        """Kubernetes Pod ìƒíƒœ ì²´í¬"""
        issues = []
        
        try:
            # Pod ëª©ë¡ ì¡°íšŒ
            pods = self.k8s_core_v1.list_namespaced_pod(namespace=KUBERNETES_NAMESPACE)
            
            for pod in pods.items:
                if not pod.metadata.name.startswith('hankook-'):
                    continue
                
                # Pod ìƒíƒœ ë¶„ì„
                if pod.status.phase != 'Running':
                    issues.append(HealthIssue(
                        component=f"pod-{pod.metadata.name}",
                        issue_type='pod_not_running',
                        severity=Severity.ERROR,
                        description=f"Pod {pod.metadata.name}ì´ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹˜: {pod.status.phase}",
                        metrics={'phase': pod.status.phase},
                        timestamp=datetime.now(),
                        recovery_actions=[RecoveryAction.RESTART_POD]
                    ))
                
                # ì¬ì‹œì‘ íšŸìˆ˜ ì²´í¬
                restart_count = 0
                if pod.status.container_statuses:
                    restart_count = sum(container.restart_count for container in pod.status.container_statuses)
                
                if restart_count > 5:
                    issues.append(HealthIssue(
                        component=f"pod-{pod.metadata.name}",
                        issue_type='high_restart_count',
                        severity=Severity.WARNING,
                        description=f"Pod {pod.metadata.name} ì¬ì‹œì‘ íšŸìˆ˜ ê³¼ë‹¤: {restart_count}",
                        metrics={'restart_count': restart_count},
                        timestamp=datetime.now(),
                        recovery_actions=[RecoveryAction.SCALE_UP, RecoveryAction.UPDATE_CONFIG]
                    ))
                    
        except Exception as e:
            logger.error(f"âŒ Kubernetes Pod ì²´í¬ ì˜¤ë¥˜: {str(e)}")
        
        return issues

    async def check_system_resources(self) -> List[HealthIssue]:
        """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì²´í¬"""
        issues = []
        
        try:
            # CPU, ë©”ëª¨ë¦¬, ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰ ì²´í¬
            cpu_percent = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            
            metrics = {
                'cpu_usage_percent': cpu_percent,
                'memory_usage_percent': memory.percent,
                'disk_usage_percent': disk.percent
            }
            
            # ê·œì¹™ ê¸°ë°˜ ì´ìŠˆ íƒì§€
            for rule_name, rule in self.recovery_rules.items():
                if any(keyword in rule_name for keyword in ['cpu', 'memory', 'disk']) and rule['condition'](metrics):
                    issues.append(HealthIssue(
                        component='system-resources',
                        issue_type=rule_name,
                        severity=rule['severity'],
                        description=f"ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì´ìŠˆ ê°ì§€: {rule_name}",
                        metrics=metrics,
                        timestamp=datetime.now(),
                        recovery_actions=rule['actions'],
                        cooldown_period=rule['cooldown']
                    ))
                    
        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì²´í¬ ì˜¤ë¥˜: {str(e)}")
        
        return issues

    async def check_sensor_connectivity(self) -> List[HealthIssue]:
        """ì„¼ì„œ ì—°ê²°ì„± ì²´í¬"""
        issues = []
        
        try:
            async with self.session.get(f"{API_BASE_URL}/sensors/status") as response:
                if response.status == 200:
                    data = await response.json()
                    
                    total_sensors = data.get('total_sensors', 0)
                    offline_sensors = data.get('offline_sensors', 0)
                    
                    if total_sensors > 0:
                        offline_rate = offline_sensors / total_sensors
                        
                        if offline_rate > 0.3:  # 30% ì´ìƒ ì˜¤í”„ë¼ì¸
                            issues.append(HealthIssue(
                                component='sensor-network',
                                issue_type='high_offline_rate',
                                severity=Severity.CRITICAL if offline_rate > 0.5 else Severity.WARNING,
                                description=f"ì„¼ì„œ ì˜¤í”„ë¼ì¸ ë¹„ìœ¨ ë†’ìŒ: {offline_rate:.1%}",
                                metrics={'offline_rate': offline_rate, 'offline_sensors': offline_sensors},
                                timestamp=datetime.now(),
                                recovery_actions=[RecoveryAction.RESTART_SERVICE, RecoveryAction.FAILOVER],
                                auto_recoverable=False  # ë¬¼ë¦¬ì  ì„¼ì„œ ì´ìŠˆëŠ” ìë™ ë³µêµ¬ ë¶ˆê°€
                            ))
                            
        except Exception as e:
            logger.error(f"âŒ ì„¼ì„œ ì—°ê²°ì„± ì²´í¬ ì˜¤ë¥˜: {str(e)}")
        
        return issues

    async def analyze_and_plan_recovery(self, health_issues: List[HealthIssue]) -> List[Tuple[HealthIssue, RecoveryAction]]:
        """ì´ìŠˆ ë¶„ì„ ë° ë³µêµ¬ ê³„íš ìˆ˜ë¦½"""
        recovery_plan = []
        
        # ì‹¬ê°ë„ë³„ ì •ë ¬
        sorted_issues = sorted(health_issues, key=lambda x: x.severity.value, reverse=True)
        
        for issue in sorted_issues:
            if not issue.auto_recoverable:
                logger.warning(f"ìë™ ë³µêµ¬ ë¶ˆê°€ ì´ìŠˆ: {issue.component} - {issue.issue_type}")
                continue
            
            # ì¿¨ë‹¤ìš´ ì²´í¬
            cooldown_key = f"{issue.component}_{issue.issue_type}"
            if cooldown_key in self.action_cooldowns:
                last_action_time = self.action_cooldowns[cooldown_key]
                if datetime.now() - last_action_time < timedelta(seconds=issue.cooldown_period):
                    logger.debug(f"ì¿¨ë‹¤ìš´ ì¤‘: {cooldown_key}")
                    continue
            
            # ë³µêµ¬ ì•¡ì…˜ ì„ íƒ
            if issue.recovery_actions:
                # ì²« ë²ˆì§¸ ì•¡ì…˜ë¶€í„° ì‹œë„
                selected_action = issue.recovery_actions[0]
                recovery_plan.append((issue, selected_action))
                
                # ì¿¨ë‹¤ìš´ ì„¤ì •
                self.action_cooldowns[cooldown_key] = datetime.now()
        
        logger.info(f"ğŸ¯ ë³µêµ¬ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ: {len(recovery_plan)}ê°œ ì•¡ì…˜")
        return recovery_plan

    async def execute_recovery_plan(self, recovery_plan: List[Tuple[HealthIssue, RecoveryAction]]):
        """ë³µêµ¬ ê³„íš ì‹¤í–‰"""
        logger.info(f"ğŸ”§ ë³µêµ¬ ê³„íš ì‹¤í–‰ ì‹œì‘: {len(recovery_plan)}ê°œ ì•¡ì…˜")
        
        recovery_tasks = []
        for issue, action in recovery_plan:
            task = asyncio.create_task(self.execute_recovery_action(issue, action))
            recovery_tasks.append(task)
        
        # ëª¨ë“  ë³µêµ¬ ì•¡ì…˜ ë³‘ë ¬ ì‹¤í–‰
        results = await asyncio.gather(*recovery_tasks, return_exceptions=True)
        
        # ê²°ê³¼ ì²˜ë¦¬
        for i, result in enumerate(results):
            if isinstance(result, RecoveryResult):
                self.recovery_history.append(result)
                recovery_actions_total.labels(
                    action_type=result.action.value,
                    target_service=result.target
                ).inc()
                
                if result.success:
                    logger.info(f"âœ… ë³µêµ¬ ì„±ê³µ: {result.action.value} - {result.target}")
                    await self.send_recovery_notification(result, success=True)
                else:
                    logger.error(f"âŒ ë³µêµ¬ ì‹¤íŒ¨: {result.action.value} - {result.target}: {result.message}")
                    await self.send_recovery_notification(result, success=False)
            else:
                logger.error(f"âŒ ë³µêµ¬ ì•¡ì…˜ ì‹¤í–‰ ì˜¤ë¥˜: {str(result)}")

    async def execute_recovery_action(self, issue: HealthIssue, action: RecoveryAction) -> RecoveryResult:
        """ê°œë³„ ë³µêµ¬ ì•¡ì…˜ ì‹¤í–‰"""
        start_time = time.time()
        
        try:
            if action == RecoveryAction.RESTART_POD:
                success, message = await self.restart_pod(issue.component)
            elif action == RecoveryAction.SCALE_UP:
                success, message = await self.scale_deployment(issue.component, scale_up=True)
            elif action == RecoveryAction.SCALE_DOWN:
                success, message = await self.scale_deployment(issue.component, scale_up=False)
            elif action == RecoveryAction.RESTART_SERVICE:
                success, message = await self.restart_service(issue.component)
            elif action == RecoveryAction.CLEAR_CACHE:
                success, message = await self.clear_cache(issue.component)
            elif action == RecoveryAction.ROTATE_LOGS:
                success, message = await self.rotate_logs(issue.component)
            elif action == RecoveryAction.UPDATE_CONFIG:
                success, message = await self.update_config(issue.component)
            elif action == RecoveryAction.FAILOVER:
                success, message = await self.perform_failover(issue.component)
            elif action == RecoveryAction.CIRCUIT_BREAKER:
                success, message = await self.activate_circuit_breaker(issue.component)
            elif action == RecoveryAction.CLEANUP_RESOURCES:
                success, message = await self.cleanup_resources(issue.component)
            elif action == RecoveryAction.REBALANCE_LOAD:
                success, message = await self.rebalance_load(issue.component)
            else:
                success, message = False, f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ì•¡ì…˜: {action.value}"
            
            duration = time.time() - start_time
            
            return RecoveryResult(
                action=action,
                target=issue.component,
                success=success,
                duration=duration,
                message=message,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            duration = time.time() - start_time
            return RecoveryResult(
                action=action,
                target=issue.component,
                success=False,
                duration=duration,
                message=f"ë³µêµ¬ ì•¡ì…˜ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}",
                timestamp=datetime.now()
            )

    async def restart_pod(self, component: str) -> Tuple[bool, str]:
        """Pod ì¬ì‹œì‘"""
        try:
            # Pod ì´ë¦„ì—ì„œ deployment ì´ë¦„ ì¶”ì¶œ
            deployment_name = component.replace('pod-', '').split('-')[0]
            if not deployment_name.startswith('hankook-'):
                deployment_name = f"hankook-{deployment_name}"
            
            # Deployment ì¬ì‹œì‘ (Rolling Update)
            body = {
                'spec': {
                    'template': {
                        'metadata': {
                            'annotations': {
                                'kubectl.kubernetes.io/restartedAt': datetime.now().isoformat()
                            }
                        }
                    }
                }
            }
            
            self.k8s_apps_v1.patch_namespaced_deployment(
                name=deployment_name,
                namespace=KUBERNETES_NAMESPACE,
                body=body
            )
            
            return True, f"Pod ì¬ì‹œì‘ ì„±ê³µ: {deployment_name}"
            
        except Exception as e:
            return False, f"Pod ì¬ì‹œì‘ ì‹¤íŒ¨: {str(e)}"

    async def scale_deployment(self, component: str, scale_up: bool = True) -> Tuple[bool, str]:
        """Deployment ìŠ¤ì¼€ì¼ë§"""
        try:
            deployment_name = component.replace('pod-', '').split('-')[0]
            if not deployment_name.startswith('hankook-'):
                deployment_name = f"hankook-{deployment_name}"
            
            # í˜„ì¬ ë ˆí”Œë¦¬ì¹´ ìˆ˜ ì¡°íšŒ
            deployment = self.k8s_apps_v1.read_namespaced_deployment(
                name=deployment_name,
                namespace=KUBERNETES_NAMESPACE
            )
            
            current_replicas = deployment.spec.replicas
            
            if scale_up:
                new_replicas = min(current_replicas + 1, 10)  # ìµœëŒ€ 10ê°œ
            else:
                new_replicas = max(current_replicas - 1, 1)   # ìµœì†Œ 1ê°œ
            
            if new_replicas == current_replicas:
                return True, f"ìŠ¤ì¼€ì¼ë§ ë¶ˆí•„ìš”: {deployment_name} (í˜„ì¬: {current_replicas})"
            
            # ìŠ¤ì¼€ì¼ë§ ì‹¤í–‰
            body = {'spec': {'replicas': new_replicas}}
            self.k8s_apps_v1.patch_namespaced_deployment(
                name=deployment_name,
                namespace=KUBERNETES_NAMESPACE,
                body=body
            )
            
            action = "ìŠ¤ì¼€ì¼ ì—…" if scale_up else "ìŠ¤ì¼€ì¼ ë‹¤ìš´"
            return True, f"{action} ì„±ê³µ: {deployment_name} ({current_replicas} â†’ {new_replicas})"
            
        except Exception as e:
            return False, f"ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨: {str(e)}"

    async def restart_service(self, component: str) -> Tuple[bool, str]:
        """ì„œë¹„ìŠ¤ ì¬ì‹œì‘ (Pod ì¬ì‹œì‘ê³¼ ë™ì¼)"""
        return await self.restart_pod(component)

    async def clear_cache(self, component: str) -> Tuple[bool, str]:
        """ìºì‹œ í´ë¦¬ì–´"""
        try:
            if 'redis' in component:
                # Redis ìºì‹œ í´ë¦¬ì–´
                self.redis_client.flushdb()
                return True, "Redis ìºì‹œ í´ë¦¬ì–´ ì™„ë£Œ"
            elif 'api' in component:
                # API ìºì‹œ í´ë¦¬ì–´ (API ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ)
                async with self.session.post(f"{API_BASE_URL}/admin/clear-cache") as response:
                    if response.status == 200:
                        return True, "API ìºì‹œ í´ë¦¬ì–´ ì™„ë£Œ"
                    else:
                        return False, f"API ìºì‹œ í´ë¦¬ì–´ ì‹¤íŒ¨: HTTP {response.status}"
            else:
                return False, f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ìºì‹œ í´ë¦¬ì–´: {component}"
                
        except Exception as e:
            return False, f"ìºì‹œ í´ë¦¬ì–´ ì‹¤íŒ¨: {str(e)}"

    async def rotate_logs(self, component: str) -> Tuple[bool, str]:
        """ë¡œê·¸ ë¡œí…Œì´ì…˜"""
        try:
            # Kubernetesì—ì„œëŠ” ë¡œê·¸ ë¡œí…Œì´ì…˜ì´ ìë™ìœ¼ë¡œ ì²˜ë¦¬ë˜ë¯€ë¡œ
            # ì—¬ê¸°ì„œëŠ” ì˜¤ë˜ëœ ë¡œê·¸ íŒŒì¼ ì •ë¦¬ë¥¼ ì‹œë®¬ë ˆì´ì…˜
            
            if 'database' in component:
                # ë°ì´í„°ë² ì´ìŠ¤ ë¡œê·¸ ì •ë¦¬ (PostgreSQL)
                conn = psycopg2.connect(
                    host=POSTGRES_HOST,
                    port=5432,
                    database='hankook_sensors',
                    user='hankook',
                    password=os.getenv('POSTGRES_PASSWORD', 'password')
                )
                
                with conn.cursor() as cursor:
                    # ì˜¤ë˜ëœ ë¡œê·¸ ì—”íŠ¸ë¦¬ ì‚­ì œ
                    cursor.execute("""
                        DELETE FROM audit.activity_logs 
                        WHERE timestamp < NOW() - INTERVAL '30 days'
                    """)
                    deleted_rows = cursor.rowcount
                
                conn.commit()
                conn.close()
                
                return True, f"ë°ì´í„°ë² ì´ìŠ¤ ë¡œê·¸ ì •ë¦¬ ì™„ë£Œ: {deleted_rows}ê°œ ë ˆì½”ë“œ ì‚­ì œ"
            else:
                return True, f"ë¡œê·¸ ë¡œí…Œì´ì…˜ ì™„ë£Œ: {component}"
                
        except Exception as e:
            return False, f"ë¡œê·¸ ë¡œí…Œì´ì…˜ ì‹¤íŒ¨: {str(e)}"

    async def update_config(self, component: str) -> Tuple[bool, str]:
        """ì„¤ì • ì—…ë°ì´íŠ¸"""
        try:
            # ConfigMap ì—…ë°ì´íŠ¸ ë¡œì§
            # ì‹¤ì œë¡œëŠ” êµ¬ì²´ì ì¸ ì„¤ì • ë³€ê²½ ë¡œì§ì´ í•„ìš”
            
            return True, f"ì„¤ì • ì—…ë°ì´íŠ¸ ì™„ë£Œ: {component}"
            
        except Exception as e:
            return False, f"ì„¤ì • ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {str(e)}"

    async def perform_failover(self, component: str) -> Tuple[bool, str]:
        """í˜ì¼ì˜¤ë²„ ìˆ˜í–‰"""
        try:
            # ê°„ë‹¨í•œ í˜ì¼ì˜¤ë²„: ë‹¤ë¥¸ ê°€ìš© ì˜ì—­ìœ¼ë¡œ íŠ¸ë˜í”½ ë¼ìš°íŒ…
            # ì‹¤ì œë¡œëŠ” ë¡œë“œë°¸ëŸ°ì„œ ì„¤ì • ë³€ê²½ ë“±ì´ í•„ìš”
            
            return True, f"í˜ì¼ì˜¤ë²„ ì™„ë£Œ: {component}"
            
        except Exception as e:
            return False, f"í˜ì¼ì˜¤ë²„ ì‹¤íŒ¨: {str(e)}"

    async def activate_circuit_breaker(self, component: str) -> Tuple[bool, str]:
        """ì„œí‚· ë¸Œë ˆì´ì»¤ í™œì„±í™”"""
        try:
            # ì„œí‚· ë¸Œë ˆì´ì»¤ ìƒíƒœ ì„¤ì •
            self.system_status['circuit_breakers'][component] = {
                'active': True,
                'activated_at': datetime.now(),
                'failure_count': 0,
                'next_retry': datetime.now() + timedelta(minutes=5)
            }
            
            return True, f"ì„œí‚· ë¸Œë ˆì´ì»¤ í™œì„±í™”: {component}"
            
        except Exception as e:
            return False, f"ì„œí‚· ë¸Œë ˆì´ì»¤ í™œì„±í™” ì‹¤íŒ¨: {str(e)}"

    async def cleanup_resources(self, component: str) -> Tuple[bool, str]:
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            cleaned_items = []
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if 'disk' in component or 'system' in component:
                # ì‹¤ì œë¡œëŠ” /tmp ë””ë ‰í† ë¦¬ ì •ë¦¬ ë“±
                cleaned_items.append("ì„ì‹œ íŒŒì¼")
            
            # ë¯¸ì‚¬ìš© Docker ì´ë¯¸ì§€ ì •ë¦¬
            if self.docker_client:
                try:
                    self.docker_client.images.prune()
                    cleaned_items.append("Docker ì´ë¯¸ì§€")
                except:
                    pass
            
            # ì˜¤ë˜ëœ ë©”íŠ¸ë¦­ ë°ì´í„° ì •ë¦¬
            if 'database' in component:
                conn = psycopg2.connect(
                    host=POSTGRES_HOST,
                    port=5432,
                    database='hankook_sensors',
                    user='hankook',
                    password=os.getenv('POSTGRES_PASSWORD', 'password')
                )
                
                with conn.cursor() as cursor:
                    cursor.execute("""
                        DELETE FROM monitoring.system_health 
                        WHERE timestamp < NOW() - INTERVAL '7 days'
                    """)
                    deleted_rows = cursor.rowcount
                
                conn.commit()
                conn.close()
                
                if deleted_rows > 0:
                    cleaned_items.append(f"ëª¨ë‹ˆí„°ë§ ë°ì´í„° ({deleted_rows}ê°œ)")
            
            return True, f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ: {', '.join(cleaned_items)}"
            
        except Exception as e:
            return False, f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹¤íŒ¨: {str(e)}"

    async def rebalance_load(self, component: str) -> Tuple[bool, str]:
        """ë¡œë“œ ë°¸ëŸ°ì‹± ì¬ì¡°ì •"""
        try:
            # ì‹¤ì œë¡œëŠ” ë¡œë“œë°¸ëŸ°ì„œ ê°€ì¤‘ì¹˜ ì¡°ì •, íŠ¸ë˜í”½ ë¶„ì‚° ë“±
            # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜
            
            return True, f"ë¡œë“œ ë°¸ëŸ°ì‹± ì¬ì¡°ì • ì™„ë£Œ: {component}"
            
        except Exception as e:
            return False, f"ë¡œë“œ ë°¸ëŸ°ì‹± ì¬ì¡°ì • ì‹¤íŒ¨: {str(e)}"

    async def predictive_scaling(self):
        """ì˜ˆì¸¡ì  ìŠ¤ì¼€ì¼ë§"""
        try:
            if self.scaling_predictor is None:
                await self.train_scaling_model()
                return
            
            # í˜„ì¬ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
            current_metrics = await self.collect_scaling_metrics()
            
            if not current_metrics:
                return
            
            # í–¥í›„ ë¡œë“œ ì˜ˆì¸¡
            features = np.array([list(current_metrics.values())]).reshape(1, -1)
            features_scaled = self.scaling_scaler.transform(features)
            
            predicted_load = self.scaling_predictor.predict(features_scaled)[0]
            
            # ìŠ¤ì¼€ì¼ë§ ê²°ì •
            current_hour = datetime.now().hour
            
            # í”¼í¬ ì‹œê°„ëŒ€ ì˜ˆì¸¡ (9-11ì‹œ, 14-16ì‹œ, 19-21ì‹œ)
            peak_hours = [9, 10, 11, 14, 15, 16, 19, 20, 21]
            
            if predicted_load > 0.8 or current_hour in peak_hours:
                # ì‚¬ì „ ìŠ¤ì¼€ì¼ ì—…
                await self.proactive_scale_up()
            elif predicted_load < 0.3 and current_hour not in peak_hours:
                # ì‚¬ì „ ìŠ¤ì¼€ì¼ ë‹¤ìš´
                await self.proactive_scale_down()
            
            logger.debug(f"ğŸ”® ì˜ˆì¸¡ì  ìŠ¤ì¼€ì¼ë§: ì˜ˆìƒ ë¡œë“œ {predicted_load:.2f}")
            
        except Exception as e:
            logger.error(f"âŒ ì˜ˆì¸¡ì  ìŠ¤ì¼€ì¼ë§ ì˜¤ë¥˜: {str(e)}")

    async def train_scaling_model(self):
        """ìŠ¤ì¼€ì¼ë§ ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨"""
        try:
            # ê³¼ê±° ë©”íŠ¸ë¦­ ë°ì´í„°ë¡œ ëª¨ë¸ í›ˆë ¨
            # ì‹¤ì œë¡œëŠ” ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ í›ˆë ¨
            
            # ë”ë¯¸ ë°ì´í„°ë¡œ ëª¨ë¸ ìƒì„±
            X = np.random.rand(1000, 5)  # 5ê°œ íŠ¹ì„±
            y = np.random.rand(1000)     # ë¡œë“œ ì˜ˆì¸¡ê°’
            
            self.scaling_predictor = RandomForestRegressor(n_estimators=100, random_state=42)
            self.scaling_predictor.fit(self.scaling_scaler.fit_transform(X), y)
            
            logger.info("ğŸ§  ìŠ¤ì¼€ì¼ë§ ì˜ˆì¸¡ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"âŒ ìŠ¤ì¼€ì¼ë§ ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {str(e)}")

    async def collect_scaling_metrics(self) -> Dict[str, float]:
        """ìŠ¤ì¼€ì¼ë§ì„ ìœ„í•œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        try:
            metrics = {}
            
            # API ë©”íŠ¸ë¦­
            async with self.session.get(f"{API_BASE_URL}/metrics") as response:
                if response.status == 200:
                    api_metrics = self.parse_prometheus_metrics(await response.text())
                    metrics.update({
                        'api_response_time': api_metrics.get('avg_response_time', 0),
                        'api_request_rate': api_metrics.get('request_rate', 0),
                        'api_error_rate': api_metrics.get('error_rate', 0)
                    })
            
            # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­
            metrics.update({
                'cpu_usage': psutil.cpu_percent(),
                'memory_usage': psutil.virtual_memory().percent
            })
            
            return metrics
            
        except Exception as e:
            logger.error(f"âŒ ìŠ¤ì¼€ì¼ë§ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ì˜¤ë¥˜: {str(e)}")
            return {}

    async def proactive_scale_up(self):
        """ì‚¬ì „ ìŠ¤ì¼€ì¼ ì—…"""
        try:
            deployments = ['hankook-api', 'hankook-frontend']
            
            for deployment in deployments:
                current_deployment = self.k8s_apps_v1.read_namespaced_deployment(
                    name=deployment,
                    namespace=KUBERNETES_NAMESPACE
                )
                
                current_replicas = current_deployment.spec.replicas
                if current_replicas < 5:  # ìµœëŒ€ 5ê°œê¹Œì§€
                    new_replicas = current_replicas + 1
                    
                    body = {'spec': {'replicas': new_replicas}}
                    self.k8s_apps_v1.patch_namespaced_deployment(
                        name=deployment,
                        namespace=KUBERNETES_NAMESPACE,
                        body=body
                    )
                    
                    logger.info(f"ğŸš€ ì‚¬ì „ ìŠ¤ì¼€ì¼ ì—…: {deployment} ({current_replicas} â†’ {new_replicas})")
                    
        except Exception as e:
            logger.error(f"âŒ ì‚¬ì „ ìŠ¤ì¼€ì¼ ì—… ì‹¤íŒ¨: {str(e)}")

    async def proactive_scale_down(self):
        """ì‚¬ì „ ìŠ¤ì¼€ì¼ ë‹¤ìš´"""
        try:
            deployments = ['hankook-api', 'hankook-frontend']
            
            for deployment in deployments:
                current_deployment = self.k8s_apps_v1.read_namespaced_deployment(
                    name=deployment,
                    namespace=KUBERNETES_NAMESPACE
                )
                
                current_replicas = current_deployment.spec.replicas
                if current_replicas > 2:  # ìµœì†Œ 2ê°œ ìœ ì§€
                    new_replicas = current_replicas - 1
                    
                    body = {'spec': {'replicas': new_replicas}}
                    self.k8s_apps_v1.patch_namespaced_deployment(
                        name=deployment,
                        namespace=KUBERNETES_NAMESPACE,
                        body=body
                    )
                    
                    logger.info(f"ğŸ“‰ ì‚¬ì „ ìŠ¤ì¼€ì¼ ë‹¤ìš´: {deployment} ({current_replicas} â†’ {new_replicas})")
                    
        except Exception as e:
            logger.error(f"âŒ ì‚¬ì „ ìŠ¤ì¼€ì¼ ë‹¤ìš´ ì‹¤íŒ¨: {str(e)}")

    async def chaos_engineering_test(self):
        """ì¹´ì˜¤ìŠ¤ ì—”ì§€ë‹ˆì–´ë§ í…ŒìŠ¤íŠ¸"""
        if not ENABLE_CHAOS_ENGINEERING:
            return
        
        try:
            logger.info("ğŸ”¥ ì¹´ì˜¤ìŠ¤ ì—”ì§€ë‹ˆì–´ë§ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
            
            # ëœë¤í•˜ê²Œ í…ŒìŠ¤íŠ¸ ì„ íƒ
            tests = [
                self.chaos_pod_kill,
                self.chaos_network_delay,
                self.chaos_cpu_stress,
                self.chaos_memory_stress
            ]
            
            selected_test = np.random.choice(tests)
            await selected_test()
            
            # 5ë¶„ í›„ ë³µêµ¬ í™•ì¸
            await asyncio.sleep(300)
            await self.verify_system_recovery()
            
        except Exception as e:
            logger.error(f"âŒ ì¹´ì˜¤ìŠ¤ ì—”ì§€ë‹ˆì–´ë§ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")

    async def chaos_pod_kill(self):
        """ì¹´ì˜¤ìŠ¤: Pod ì¢…ë£Œ í…ŒìŠ¤íŠ¸"""
        try:
            # ëœë¤í•˜ê²Œ Pod ì„ íƒ (ì¤‘ìš”í•˜ì§€ ì•Šì€ Pod)
            pods = self.k8s_core_v1.list_namespaced_pod(namespace=KUBERNETES_NAMESPACE)
            
            test_candidates = []
            for pod in pods.items:
                if (pod.metadata.name.startswith('hankook-') and 
                    'postgres' not in pod.metadata.name and 
                    pod.status.phase == 'Running'):
                    test_candidates.append(pod.metadata.name)
            
            if test_candidates:
                target_pod = np.random.choice(test_candidates)
                
                logger.info(f"ğŸ”¥ ì¹´ì˜¤ìŠ¤: Pod ì¢…ë£Œ í…ŒìŠ¤íŠ¸ - {target_pod}")
                
                self.k8s_core_v1.delete_namespaced_pod(
                    name=target_pod,
                    namespace=KUBERNETES_NAMESPACE
                )
                
                recovery_actions_total.labels(
                    action_type=RecoveryAction.CHAOS_TEST.value,
                    target_service=target_pod
                ).inc()
                
        except Exception as e:
            logger.error(f"âŒ ì¹´ì˜¤ìŠ¤ Pod ì¢…ë£Œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")

    async def chaos_network_delay(self):
        """ì¹´ì˜¤ìŠ¤: ë„¤íŠ¸ì›Œí¬ ì§€ì—° í…ŒìŠ¤íŠ¸"""
        # ì‹¤ì œë¡œëŠ” ë„¤íŠ¸ì›Œí¬ ì§€ì—°ì„ ì£¼ì…í•˜ëŠ” ë„êµ¬ í•„ìš” (ì˜ˆ: Chaos Mesh)
        logger.info("ğŸ”¥ ì¹´ì˜¤ìŠ¤: ë„¤íŠ¸ì›Œí¬ ì§€ì—° í…ŒìŠ¤íŠ¸ (ì‹œë®¬ë ˆì´ì…˜)")

    async def chaos_cpu_stress(self):
        """ì¹´ì˜¤ìŠ¤: CPU ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸"""
        # ì‹¤ì œë¡œëŠ” CPU ë¶€í•˜ë¥¼ ì£¼ì…í•˜ëŠ” ë„êµ¬ í•„ìš”
        logger.info("ğŸ”¥ ì¹´ì˜¤ìŠ¤: CPU ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ (ì‹œë®¬ë ˆì´ì…˜)")

    async def chaos_memory_stress(self):
        """ì¹´ì˜¤ìŠ¤: ë©”ëª¨ë¦¬ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸"""
        # ì‹¤ì œë¡œëŠ” ë©”ëª¨ë¦¬ ë¶€í•˜ë¥¼ ì£¼ì…í•˜ëŠ” ë„êµ¬ í•„ìš”
        logger.info("ğŸ”¥ ì¹´ì˜¤ìŠ¤: ë©”ëª¨ë¦¬ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ (ì‹œë®¬ë ˆì´ì…˜)")

    async def verify_system_recovery(self):
        """ì‹œìŠ¤í…œ ë³µêµ¬ ê²€ì¦"""
        try:
            logger.info("ğŸ” ì¹´ì˜¤ìŠ¤ í…ŒìŠ¤íŠ¸ í›„ ì‹œìŠ¤í…œ ë³µêµ¬ ê²€ì¦...")
            
            # ëª¨ë“  ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
            health_issues = await self.perform_comprehensive_health_check()
            
            critical_issues = [issue for issue in health_issues if issue.severity.value >= Severity.ERROR.value]
            
            if not critical_issues:
                logger.info("âœ… ì‹œìŠ¤í…œ ë³µêµ¬ ê²€ì¦ ì™„ë£Œ - ëª¨ë“  ì„œë¹„ìŠ¤ ì •ìƒ")
            else:
                logger.warning(f"âš ï¸ ë³µêµ¬ ë¯¸ì™„ë£Œ ì´ìŠˆ {len(critical_issues)}ê°œ ë°œê²¬")
                
                # ì¶”ê°€ ë³µêµ¬ ì•¡ì…˜ ì‹¤í–‰
                recovery_plan = await self.analyze_and_plan_recovery(critical_issues)
                if recovery_plan:
                    await self.execute_recovery_plan(recovery_plan)
                    
        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ ë³µêµ¬ ê²€ì¦ ì˜¤ë¥˜: {str(e)}")

    def parse_prometheus_metrics(self, metrics_text: str, prefix: str = '') -> Dict[str, float]:
        """Prometheus ë©”íŠ¸ë¦­ íŒŒì‹±"""
        metrics = {}
        
        for line in metrics_text.split('\n'):
            if line.startswith('#') or not line.strip():
                continue
            
            try:
                if ' ' in line:
                    metric_name, value = line.rsplit(' ', 1)
                    
                    if prefix and metric_name.startswith(prefix):
                        clean_name = metric_name.replace(prefix, '').split('{')[0]
                        metrics[clean_name] = float(value)
                    elif not prefix:
                        clean_name = metric_name.split('{')[0]
                        metrics[clean_name] = float(value)
                        
            except (ValueError, IndexError):
                continue
        
        return metrics

    async def update_system_status(self, health_issues: List[HealthIssue]):
        """ì‹œìŠ¤í…œ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        self.system_status['active_issues'] = health_issues
        
        # ì „ì²´ ì‹œìŠ¤í…œ í—¬ìŠ¤ ìŠ¤ì½”ì–´ ê³„ì‚°
        if not health_issues:
            health_score = 100.0
        else:
            # ì‹¬ê°ë„ë³„ ê°€ì¤‘ì¹˜ ì ìš©
            severity_weights = {
                Severity.INFO: 0.1,
                Severity.WARNING: 0.3,
                Severity.ERROR: 0.6,
                Severity.CRITICAL: 0.8,
                Severity.EMERGENCY: 1.0
            }
            
            total_impact = sum(severity_weights[issue.severity] for issue in health_issues)
            health_score = max(0, 100 - (total_impact * 10))
        
        system_health_score.set(health_score)
        
        # Redisì— ìƒíƒœ ì €ì¥
        try:
            status_data = {
                'timestamp': datetime.now().isoformat(),
                'health_score': health_score,
                'active_issues_count': len(health_issues),
                'recovery_actions_today': len([r for r in self.recovery_history 
                                             if r.timestamp.date() == datetime.now().date()]),
                'system_status': 'healthy' if health_score > 80 else 'degraded' if health_score > 50 else 'critical'
            }
            
            self.redis_client.setex(
                'system_status',
                300,  # 5ë¶„ TTL
                json.dumps(status_data)
            )
            
        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ ìƒíƒœ ì €ì¥ ì˜¤ë¥˜: {str(e)}")

    def update_prometheus_metrics(self):
        """Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸"""
        try:
            # ë³µêµ¬ ì„±ê³µë¥  ê³„ì‚°
            if self.recovery_history:
                recent_actions = [r for r in self.recovery_history 
                                if r.timestamp > datetime.now() - timedelta(hours=24)]
                
                if recent_actions:
                    action_types = {}
                    for action in recent_actions:
                        action_type = action.action.value
                        if action_type not in action_types:
                            action_types[action_type] = {'total': 0, 'success': 0}
                        
                        action_types[action_type]['total'] += 1
                        if action.success:
                            action_types[action_type]['success'] += 1
                    
                    for action_type, stats in action_types.items():
                        success_rate = stats['success'] / stats['total'] if stats['total'] > 0 else 0
                        recovery_success_rate.labels(action_type=action_type).set(success_rate)
            
            # ì˜ˆì¸¡ ëª¨ë¸ ì •í™•ë„ (ë”ë¯¸ ê°’)
            if self.scaling_predictor:
                prediction_accuracy.set(0.85)  # ì‹¤ì œë¡œëŠ” ëª¨ë¸ ê²€ì¦ ê²°ê³¼ ì‚¬ìš©
                
        except Exception as e:
            logger.error(f"âŒ Prometheus ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {str(e)}")

    async def send_recovery_notification(self, result: RecoveryResult, success: bool):
        """ë³µêµ¬ ì•Œë¦¼ ì „ì†¡"""
        if not SLACK_WEBHOOK:
            return
        
        try:
            emoji = "âœ…" if success else "âŒ"
            color = "good" if success else "danger"
            
            message = {
                "attachments": [{
                    "color": color,
                    "title": f"{emoji} ìë™ ë³µêµ¬ {'ì„±ê³µ' if success else 'ì‹¤íŒ¨'}",
                    "fields": [
                        {"title": "ì•¡ì…˜", "value": result.action.value, "short": True},
                        {"title": "ëŒ€ìƒ", "value": result.target, "short": True},
                        {"title": "ì‹¤í–‰ ì‹œê°„", "value": f"{result.duration:.2f}ì´ˆ", "short": True},
                        {"title": "ë©”ì‹œì§€", "value": result.message, "short": False}
                    ],
                    "footer": "HankookTire Self-Healing System",
                    "ts": int(result.timestamp.timestamp())
                }]
            }
            
            async with self.session.post(SLACK_WEBHOOK, json=message) as response:
                if response.status == 200:
                    logger.debug("ë³µêµ¬ ì•Œë¦¼ ì „ì†¡ ì™„ë£Œ")
                    
        except Exception as e:
            logger.error(f"âŒ ë³µêµ¬ ì•Œë¦¼ ì „ì†¡ ì˜¤ë¥˜: {str(e)}")

    async def load_predictive_models(self):
        """ì˜ˆì¸¡ ëª¨ë¸ ë¡œë“œ"""
        try:
            model_path = "/app/models/scaling_predictor.joblib"
            scaler_path = "/app/models/scaling_scaler.joblib"
            
            if os.path.exists(model_path) and os.path.exists(scaler_path):
                self.scaling_predictor = joblib.load(model_path)
                self.scaling_scaler = joblib.load(scaler_path)
                logger.info("ğŸ§  ì˜ˆì¸¡ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            else:
                logger.info("ğŸ”„ ì˜ˆì¸¡ ëª¨ë¸ ì—†ìŒ - ìƒˆë¡œ í›ˆë ¨í•©ë‹ˆë‹¤")
                await self.train_scaling_model()
                
        except Exception as e:
            logger.error(f"âŒ ì˜ˆì¸¡ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("ğŸš€ HankookTire SmartSensor ìê°€ ì¹˜ìœ  ì‹œìŠ¤í…œ ì‹œì‘")
    
    async with SelfHealingSystem() as healing_system:
        # ì§€ì†ì ì¸ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        await healing_system.continuous_health_monitoring()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        logger.info("ğŸ‘‹ ìê°€ ì¹˜ìœ  ì‹œìŠ¤í…œì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"ğŸ’¥ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
        exit(1)