#!/usr/bin/env python3
"""
HankookTire SmartSensor 2.0 - Advanced AI Engine
ì°¨ì„¸ëŒ€ AI ê¸°ë°˜ ì˜ˆì¸¡ ë¶„ì„ ì—”ì§„
"""

import asyncio
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.ensemble import IsolationForest, RandomForestRegressor
from sklearn.model_selection import train_test_split
import joblib
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
import json
from pathlib import Path

# TensorFlow for additional models
import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dense, Dropout, Attention
from tensorflow.keras.optimizers import Adam

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AdvancedLSTMModel(nn.Module):
    """ê³ ê¸‰ LSTM ëª¨ë¸ (PyTorch)"""
    
    def __init__(self, input_size: int, hidden_size: int = 128, num_layers: int = 3, dropout: float = 0.2):
        super(AdvancedLSTMModel, self).__init__()
        
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        # LSTM ë ˆì´ì–´ë“¤
        self.lstm1 = nn.LSTM(input_size, hidden_size, num_layers, 
                            batch_first=True, dropout=dropout, bidirectional=True)
        self.lstm2 = nn.LSTM(hidden_size * 2, hidden_size, 1, 
                            batch_first=True, dropout=dropout)
        
        # Attention ë©”ì»¤ë‹ˆì¦˜
        self.attention = nn.MultiheadAttention(hidden_size, num_heads=8, dropout=dropout)
        
        # ì™„ì „ì—°ê²° ë ˆì´ì–´ë“¤
        self.fc1 = nn.Linear(hidden_size, 64)
        self.fc2 = nn.Linear(64, 32)
        self.fc3 = nn.Linear(32, 1)
        
        self.dropout = nn.Dropout(dropout)
        self.relu = nn.ReLU()
        
    def forward(self, x):
        # LSTM ì²˜ë¦¬
        lstm_out1, _ = self.lstm1(x)
        lstm_out2, _ = self.lstm2(lstm_out1)
        
        # Attention ì ìš©
        lstm_out2 = lstm_out2.transpose(0, 1)  # (seq, batch, features)
        attn_out, _ = self.attention(lstm_out2, lstm_out2, lstm_out2)
        attn_out = attn_out.transpose(0, 1)  # (batch, seq, features)
        
        # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í… ì‚¬ìš©
        out = attn_out[:, -1, :]
        
        # ì™„ì „ì—°ê²° ë ˆì´ì–´
        out = self.relu(self.fc1(out))
        out = self.dropout(out)
        out = self.relu(self.fc2(out))
        out = self.dropout(out)
        out = self.fc3(out)
        
        return out

class TransformerModel(nn.Module):
    """Transformer ê¸°ë°˜ ì‹œê³„ì—´ ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self, input_size: int, d_model: int = 128, nhead: int = 8, num_layers: int = 6):
        super(TransformerModel, self).__init__()
        
        self.d_model = d_model
        self.input_projection = nn.Linear(input_size, d_model)
        
        # Positional Encoding
        self.pos_encoding = self._generate_pos_encoding(1000, d_model)
        
        # Transformer ì¸ì½”ë”
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model, 
            nhead=nhead, 
            dim_feedforward=d_model * 4,
            dropout=0.1
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # ì¶œë ¥ ë ˆì´ì–´
        self.output_layer = nn.Linear(d_model, 1)
        
    def _generate_pos_encoding(self, max_len: int, d_model: int):
        """Positional Encoding ìƒì„±"""
        pe = torch.zeros(max_len, d_model)
        position = torch.arange(0, max_len).unsqueeze(1).float()
        
        div_term = torch.exp(torch.arange(0, d_model, 2).float() * 
                           -(np.log(10000.0) / d_model))
        
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        
        return pe.unsqueeze(0)
    
    def forward(self, x):
        # ì…ë ¥ íˆ¬ì˜
        x = self.input_projection(x) * np.sqrt(self.d_model)
        
        # Positional Encoding ì¶”ê°€
        seq_len = x.size(1)
        pos_enc = self.pos_encoding[:, :seq_len, :].to(x.device)
        x = x + pos_enc
        
        # Transformer ì²˜ë¦¬ (seq_len, batch_size, d_model)
        x = x.transpose(0, 1)
        x = self.transformer(x)
        x = x.transpose(0, 1)
        
        # ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…ì˜ ì¶œë ¥
        output = self.output_layer(x[:, -1, :])
        
        return output

class HankookAIEngine:
    """í•œêµ­íƒ€ì´ì–´ ì°¨ì„¸ëŒ€ AI ì—”ì§„"""
    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        logger.info(f"AI ì—”ì§„ ì´ˆê¸°í™” - ë””ë°”ì´ìŠ¤: {self.device}")
        
        # ëª¨ë¸ ì €ì¥ ê²½ë¡œ
        self.model_path = Path("models")
        self.model_path.mkdir(exist_ok=True)
        
        # ë°ì´í„° ìŠ¤ì¼€ì¼ëŸ¬ë“¤
        self.scalers = {}
        
        # í•™ìŠµëœ ëª¨ë¸ë“¤
        self.models = {
            'tire_life_lstm': None,
            'tire_life_transformer': None,
            'anomaly_detector': None,
            'quality_predictor': None,
            'maintenance_predictor': None,
            'temperature_forecaster': None,
            'pressure_forecaster': None,
            'vibration_analyzer': None
        }
        
        # ëª¨ë¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­
        self.model_metrics = {}
        
        # ì‹¤ì‹œê°„ ì¶”ë¡  ìºì‹œ
        self.inference_cache = {}
        
    async def initialize(self):
        """AI ì—”ì§„ ì´ˆê¸°í™”"""
        logger.info("ğŸ¤– AI ì—”ì§„ ì´ˆê¸°í™” ì‹œì‘")
        
        try:
            # ì €ì¥ëœ ëª¨ë¸ ë¡œë“œ
            await self.load_models()
            
            # ì—†ëŠ” ëª¨ë¸ë“¤ì€ ê¸°ë³¸ ëª¨ë¸ë¡œ ì´ˆê¸°í™”
            await self.initialize_default_models()
            
            # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
            await self.load_scalers()
            
            logger.info("âœ… AI ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"AI ì—”ì§„ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            raise
    
    async def load_models(self):
        """ì €ì¥ëœ ëª¨ë¸ë“¤ ë¡œë“œ"""
        for model_name in self.models.keys():
            model_file = self.model_path / f"{model_name}.pth"
            if model_file.exists():
                try:
                    if model_name == 'tire_life_lstm':
                        self.models[model_name] = AdvancedLSTMModel(input_size=8)
                        self.models[model_name].load_state_dict(torch.load(model_file, map_location=self.device))
                    elif model_name == 'tire_life_transformer':
                        self.models[model_name] = TransformerModel(input_size=8)
                        self.models[model_name].load_state_dict(torch.load(model_file, map_location=self.device))
                    elif model_name == 'anomaly_detector':
                        self.models[model_name] = joblib.load(model_file)
                    
                    logger.info(f"âœ“ {model_name} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                except Exception as e:
                    logger.warning(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ({model_name}): {e}")
    
    async def initialize_default_models(self):
        """ê¸°ë³¸ ëª¨ë¸ë“¤ ì´ˆê¸°í™”"""
        # LSTM ëª¨ë¸
        if self.models['tire_life_lstm'] is None:
            self.models['tire_life_lstm'] = AdvancedLSTMModel(input_size=8).to(self.device)
            logger.info("âœ“ ê¸°ë³¸ LSTM ëª¨ë¸ ì´ˆê¸°í™”")
        
        # Transformer ëª¨ë¸
        if self.models['tire_life_transformer'] is None:
            self.models['tire_life_transformer'] = TransformerModel(input_size=8).to(self.device)
            logger.info("âœ“ ê¸°ë³¸ Transformer ëª¨ë¸ ì´ˆê¸°í™”")
        
        # ì´ìƒ íƒì§€ ëª¨ë¸
        if self.models['anomaly_detector'] is None:
            self.models['anomaly_detector'] = IsolationForest(
                contamination=0.1,
                random_state=42,
                n_estimators=200
            )
            logger.info("âœ“ ê¸°ë³¸ ì´ìƒ íƒì§€ ëª¨ë¸ ì´ˆê¸°í™”")
        
        # í’ˆì§ˆ ì˜ˆì¸¡ ëª¨ë¸
        if self.models['quality_predictor'] is None:
            self.models['quality_predictor'] = RandomForestRegressor(
                n_estimators=200,
                random_state=42,
                n_jobs=-1
            )
            logger.info("âœ“ ê¸°ë³¸ í’ˆì§ˆ ì˜ˆì¸¡ ëª¨ë¸ ì´ˆê¸°í™”")
    
    async def load_scalers(self):
        """ë°ì´í„° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ"""
        scaler_file = self.model_path / "scalers.pkl"
        if scaler_file.exists():
            try:
                self.scalers = joblib.load(scaler_file)
                logger.info("âœ“ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ê¸°ë³¸ ìŠ¤ì¼€ì¼ëŸ¬ ì´ˆê¸°í™”
        if not self.scalers:
            self.scalers = {
                'sensor_data': StandardScaler(),
                'tire_data': MinMaxScaler(),
                'quality_data': StandardScaler()
            }
            logger.info("âœ“ ê¸°ë³¸ ìŠ¤ì¼€ì¼ëŸ¬ ì´ˆê¸°í™”")
    
    async def run_inference(self, sensor_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì‹¤ì‹œê°„ AI ì¶”ë¡  ì‹¤í–‰"""
        try:
            # ë°ì´í„° ì „ì²˜ë¦¬
            processed_data = await self.preprocess_for_inference(sensor_data)
            
            # ì—¬ëŸ¬ ëª¨ë¸ë¡œ ì˜ˆì¸¡ ì‹¤í–‰
            predictions = {}
            
            # LSTM ê¸°ë°˜ íƒ€ì´ì–´ ìˆ˜ëª… ì˜ˆì¸¡
            if self.models['tire_life_lstm']:
                lstm_prediction = await self.predict_tire_life_lstm(processed_data)
                predictions['tire_life_lstm'] = lstm_prediction
            
            # Transformer ê¸°ë°˜ íƒ€ì´ì–´ ìˆ˜ëª… ì˜ˆì¸¡
            if self.models['tire_life_transformer']:
                transformer_prediction = await self.predict_tire_life_transformer(processed_data)
                predictions['tire_life_transformer'] = transformer_prediction
            
            # ì•™ìƒë¸” ì˜ˆì¸¡ (LSTM + Transformer)
            if 'tire_life_lstm' in predictions and 'tire_life_transformer' in predictions:
                ensemble_prediction = (predictions['tire_life_lstm'] + predictions['tire_life_transformer']) / 2
                predictions['tire_life_ensemble'] = ensemble_prediction
            
            # í’ˆì§ˆ ì ìˆ˜ ì˜ˆì¸¡
            quality_score = await self.predict_quality_score(processed_data)
            predictions['quality_score'] = quality_score
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence_score = await self.calculate_confidence(predictions)
            
            return {
                'predictions': predictions,
                'confidence': confidence_score,
                'timestamp': datetime.now().isoformat(),
                'model_versions': await self.get_model_versions()
            }
            
        except Exception as e:
            logger.error(f"AI ì¶”ë¡  ì˜¤ë¥˜: {e}")
            return {'error': str(e)}
    
    async def detect_anomalies(self, sensor_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì‹¤ì‹œê°„ ì´ìƒ íƒì§€"""
        try:
            # ë°ì´í„° ì „ì²˜ë¦¬
            processed_data = await self.preprocess_for_anomaly_detection(sensor_data)
            
            if len(processed_data) == 0:
                return {'anomalies': [], 'risk_level': 'low'}
            
            # ì´ìƒ íƒì§€ ì‹¤í–‰
            anomaly_scores = self.models['anomaly_detector'].decision_function(processed_data)
            is_anomaly = self.models['anomaly_detector'].predict(processed_data) == -1
            
            # ì´ìƒ ì •ë³´ ë¶„ì„
            anomalies = []
            for i, (score, is_anom) in enumerate(zip(anomaly_scores, is_anomaly)):
                if is_anom:
                    anomaly_info = await self.analyze_anomaly_details(sensor_data[i], score)
                    anomalies.append(anomaly_info)
            
            # ìœ„í—˜ ìˆ˜ì¤€ ê³„ì‚°
            risk_level = await self.calculate_risk_level(anomaly_scores)
            
            return {
                'anomalies': anomalies,
                'risk_level': risk_level,
                'total_anomalies': len(anomalies),
                'average_score': float(np.mean(anomaly_scores)),
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"ì´ìƒ íƒì§€ ì˜¤ë¥˜: {e}")
            return {'error': str(e)}
    
    async def predict_maintenance(self, sensor_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì˜ˆì¸¡ ì •ë¹„ ë¶„ì„"""
        try:
            # ë°ì´í„° ê¸°ë°˜ ì •ë¹„ ì˜ˆì¸¡
            maintenance_data = await self.analyze_maintenance_needs(sensor_data)
            
            # íƒ€ì´ì–´ë³„ ì •ë¹„ ì˜ˆì¸¡
            tire_maintenance = {}
            for i in range(4):  # 4ê°œ íƒ€ì´ì–´
                tire_data = await self.extract_tire_specific_data(sensor_data, i)
                tire_maintenance[f'tire_{i+1}'] = await self.predict_tire_maintenance(tire_data)
            
            # ì „ì²´ ì‹œìŠ¤í…œ ì •ë¹„ ì˜ˆì¸¡
            system_maintenance = await self.predict_system_maintenance(sensor_data)
            
            return {
                'tire_maintenance': tire_maintenance,
                'system_maintenance': system_maintenance,
                'maintenance_priority': await self.calculate_maintenance_priority(tire_maintenance),
                'estimated_cost': await self.estimate_maintenance_cost(tire_maintenance, system_maintenance),
                'recommended_date': await self.recommend_maintenance_date(tire_maintenance),
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"ì •ë¹„ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            return {'error': str(e)}
    
    async def preprocess_for_inference(self, sensor_data: List[Dict[str, Any]]) -> np.ndarray:
        """ì¶”ë¡ ìš© ë°ì´í„° ì „ì²˜ë¦¬"""
        features = []
        
        for data in sensor_data:
            feature_vector = [
                data.get('temperature', 0),
                data.get('humidity', 0),
                data.get('pressure', 0),
                data.get('acceleration', 0),
                data.get('light', 0),
                data.get('battery_voltage', 0),
                data.get('system_health', 0),
                data.get('quality_score', 0)
            ]
            features.append(feature_vector)
        
        features_array = np.array(features)
        
        # ìŠ¤ì¼€ì¼ë§
        if 'sensor_data' in self.scalers:
            features_array = self.scalers['sensor_data'].fit_transform(features_array)
        
        return features_array
    
    async def predict_tire_life_lstm(self, processed_data: np.ndarray) -> float:
        """LSTM ëª¨ë¸ë¡œ íƒ€ì´ì–´ ìˆ˜ëª… ì˜ˆì¸¡"""
        model = self.models['tire_life_lstm']
        model.eval()
        
        # ì‹œí€€ìŠ¤ ë°ì´í„°ë¡œ ë³€í™˜ (ë°°ì¹˜, ì‹œí€€ìŠ¤, íŠ¹ì„±)
        if len(processed_data.shape) == 2:
            # ë§ˆì§€ë§‰ 10ê°œ ë°ì´í„°í¬ì¸íŠ¸ ì‚¬ìš©
            sequence_length = min(10, len(processed_data))
            sequence_data = processed_data[-sequence_length:]
            sequence_data = sequence_data.reshape(1, sequence_length, -1)
        else:
            sequence_data = processed_data
        
        # í…ì„œ ë³€í™˜
        input_tensor = torch.FloatTensor(sequence_data).to(self.device)
        
        with torch.no_grad():
            prediction = model(input_tensor)
        
        # ì¼ ë‹¨ìœ„ë¡œ ë³€í™˜ (ê¸°ë³¸ ì˜ˆì¸¡ê°’ì€ ì •ê·œí™”ëœ ê°’)
        predicted_days = float(prediction.cpu().numpy()[0][0]) * 1095  # 3ë…„ = 1095ì¼
        
        return max(30, predicted_days)  # ìµœì†Œ 30ì¼
    
    async def predict_tire_life_transformer(self, processed_data: np.ndarray) -> float:
        """Transformer ëª¨ë¸ë¡œ íƒ€ì´ì–´ ìˆ˜ëª… ì˜ˆì¸¡"""
        model = self.models['tire_life_transformer']
        model.eval()
        
        # ì‹œí€€ìŠ¤ ë°ì´í„°ë¡œ ë³€í™˜
        if len(processed_data.shape) == 2:
            sequence_length = min(20, len(processed_data))  # TransformerëŠ” ë” ê¸´ ì‹œí€€ìŠ¤ ì‚¬ìš©
            sequence_data = processed_data[-sequence_length:]
            sequence_data = sequence_data.reshape(1, sequence_length, -1)
        else:
            sequence_data = processed_data
        
        # í…ì„œ ë³€í™˜
        input_tensor = torch.FloatTensor(sequence_data).to(self.device)
        
        with torch.no_grad():
            prediction = model(input_tensor)
        
        # ì¼ ë‹¨ìœ„ë¡œ ë³€í™˜
        predicted_days = float(prediction.cpu().numpy()[0][0]) * 1095
        
        return max(30, predicted_days)
    
    async def predict_quality_score(self, processed_data: np.ndarray) -> float:
        """í’ˆì§ˆ ì ìˆ˜ ì˜ˆì¸¡"""
        if self.models['quality_predictor'] and len(processed_data) > 0:
            # ìµœì‹  ë°ì´í„° ì‚¬ìš©
            latest_data = processed_data[-1].reshape(1, -1)
            quality_score = self.models['quality_predictor'].predict(latest_data)[0]
            return max(0, min(100, quality_score))
        
        return 85.0  # ê¸°ë³¸ê°’
    
    async def preprocess_for_anomaly_detection(self, sensor_data: List[Dict[str, Any]]) -> np.ndarray:
        """ì´ìƒ íƒì§€ìš© ë°ì´í„° ì „ì²˜ë¦¬"""
        return await self.preprocess_for_inference(sensor_data)
    
    async def analyze_anomaly_details(self, data_point: Dict[str, Any], anomaly_score: float) -> Dict[str, Any]:
        """ì´ìƒ ìƒì„¸ ë¶„ì„"""
        anomaly_types = []
        severity = "ë‚®ìŒ"
        
        # ì˜¨ë„ ì´ìƒ
        temp = data_point.get('temperature', 25)
        if temp > 60 or temp < 0:
            anomaly_types.append("ê·¹í•œ ì˜¨ë„")
            severity = "ë†’ìŒ"
        elif temp > 45 or temp < 5:
            anomaly_types.append("ë¹„ì •ìƒ ì˜¨ë„")
            severity = "ë³´í†µ"
        
        # ì••ë ¥ ì´ìƒ
        pressure = data_point.get('pressure', 1013)
        if abs(pressure - 1013) > 100:
            anomaly_types.append("ê¸°ì•• ì´ìƒ")
            severity = "ë†’ìŒ"
        
        # ì§„ë™ ì´ìƒ
        acceleration = data_point.get('acceleration', 1.0)
        if acceleration > 3.0:
            anomaly_types.append("ê³¼ë„í•œ ì§„ë™")
            severity = "ë†’ìŒ"
        
        # ì‹œìŠ¤í…œ ê±´ê°•ë„ ì´ìƒ
        health = data_point.get('system_health', 100)
        if health < 50:
            anomaly_types.append("ì‹œìŠ¤í…œ ì„±ëŠ¥ ì €í•˜")
            severity = "ë§¤ìš° ë†’ìŒ"
        
        return {
            'anomaly_types': anomaly_types if anomaly_types else ["ì•Œ ìˆ˜ ì—†ëŠ” ì´ìƒ"],
            'severity': severity,
            'anomaly_score': float(anomaly_score),
            'affected_sensors': await self.identify_affected_sensors(data_point),
            'recommended_action': await self.recommend_action(anomaly_types, severity)
        }
    
    async def calculate_risk_level(self, anomaly_scores: np.ndarray) -> str:
        """ìœ„í—˜ ìˆ˜ì¤€ ê³„ì‚°"""
        avg_score = np.mean(anomaly_scores)
        min_score = np.min(anomaly_scores)
        
        if min_score < -0.5 or avg_score < -0.3:
            return "ë§¤ìš° ë†’ìŒ"
        elif min_score < -0.3 or avg_score < -0.2:
            return "ë†’ìŒ"
        elif min_score < -0.1 or avg_score < -0.1:
            return "ë³´í†µ"
        else:
            return "ë‚®ìŒ"
    
    async def identify_affected_sensors(self, data_point: Dict[str, Any]) -> List[str]:
        """ì˜í–¥ë°›ì€ ì„¼ì„œ ì‹ë³„"""
        affected = []
        
        if data_point.get('temperature', 25) > 50:
            affected.append("DHT22 (ì˜¨ìŠµë„)")
        if abs(data_point.get('pressure', 1013) - 1013) > 50:
            affected.append("BMP280 (ê¸°ì••)")
        if data_point.get('acceleration', 1.0) > 2.0:
            affected.append("MPU6050 (ê°€ì†ë„)")
        if data_point.get('system_health', 100) < 70:
            affected.append("ì „ì²´ ì‹œìŠ¤í…œ")
        
        return affected if affected else ["ì•Œ ìˆ˜ ì—†ìŒ"]
    
    async def recommend_action(self, anomaly_types: List[str], severity: str) -> str:
        """ê¶Œì¥ ì¡°ì¹˜ ì‚¬í•­"""
        if "ì‹œìŠ¤í…œ ì„±ëŠ¥ ì €í•˜" in anomaly_types:
            return "ì¦‰ì‹œ ì‹œìŠ¤í…œ ì ê²€ ë° ì¬ì‹œì‘ í•„ìš”"
        elif "ê·¹í•œ ì˜¨ë„" in anomaly_types:
            return "ì˜¨ë„ ì œì–´ ì‹œìŠ¤í…œ ì ê²€ ë° í™˜ê¸° ê°œì„ "
        elif "ê³¼ë„í•œ ì§„ë™" in anomaly_types:
            return "ì§„ë™ ì›ì¸ ì¡°ì‚¬ ë° ì¥ë¹„ ê³ ì • ìƒíƒœ í™•ì¸"
        elif severity == "ë§¤ìš° ë†’ìŒ":
            return "ì¦‰ì‹œ ì „ë¬¸ê°€ ì ê²€ í•„ìš”"
        elif severity == "ë†’ìŒ":
            return "24ì‹œê°„ ë‚´ ì ê²€ ê¶Œì¥"
        else:
            return "ì •ê¸° ì ê²€ ì‹œ í™•ì¸"
    
    async def calculate_confidence(self, predictions: Dict[str, float]) -> float:
        """ì˜ˆì¸¡ ì‹ ë¢°ë„ ê³„ì‚°"""
        if len(predictions) < 2:
            return 0.7  # ê¸°ë³¸ ì‹ ë¢°ë„
        
        # ì—¬ëŸ¬ ëª¨ë¸ ì˜ˆì¸¡ê°’ì˜ ì¼ì¹˜ë„ ê¸°ë°˜ ì‹ ë¢°ë„ ê³„ì‚°
        values = list(predictions.values())
        variance = np.var(values)
        
        # ë¶„ì‚°ì´ ë‚®ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ë†’ìŒ
        confidence = max(0.5, min(0.95, 1.0 - (variance / 10000)))
        
        return confidence
    
    async def get_model_versions(self) -> Dict[str, str]:
        """ëª¨ë¸ ë²„ì „ ì •ë³´"""
        return {
            'lstm': 'v2.1',
            'transformer': 'v1.3',
            'anomaly_detector': 'v2.0',
            'quality_predictor': 'v1.5'
        }
    
    async def health_check(self) -> Dict[str, Any]:
        """AI ì—”ì§„ ìƒíƒœ ì²´í¬"""
        model_status = {}
        for name, model in self.models.items():
            model_status[name] = "loaded" if model is not None else "not_loaded"
        
        return {
            'status': 'healthy',
            'models': model_status,
            'device': str(self.device),
            'memory_usage': torch.cuda.memory_allocated() if torch.cuda.is_available() else 0,
            'inference_cache_size': len(self.inference_cache)
        }
    
    async def cleanup(self):
        """AI ì—”ì§„ ì •ë¦¬"""
        logger.info("ğŸ”„ AI ì—”ì§„ ì •ë¦¬ ì¤‘...")
        
        # ëª¨ë¸ ì €ì¥
        await self.save_models()
        
        # ìºì‹œ ì •ë¦¬
        self.inference_cache.clear()
        
        # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        logger.info("âœ… AI ì—”ì§„ ì •ë¦¬ ì™„ë£Œ")
    
    async def save_models(self):
        """ëª¨ë¸ ì €ì¥"""
        try:
            for name, model in self.models.items():
                if model and hasattr(model, 'state_dict'):
                    model_file = self.model_path / f"{name}.pth"
                    torch.save(model.state_dict(), model_file)
                elif model and hasattr(model, 'fit'):  # sklearn ëª¨ë¸
                    model_file = self.model_path / f"{name}.pkl"
                    joblib.dump(model, model_file)
            
            # ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥
            scaler_file = self.model_path / "scalers.pkl"
            joblib.dump(self.scalers, scaler_file)
            
            logger.info("âœ“ ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ëª¨ë¸ ì €ì¥ ì˜¤ë¥˜: {e}")
    
    # ì¶”ê°€ ì •ë¹„ ì˜ˆì¸¡ ê´€ë ¨ ë©”ì†Œë“œë“¤
    async def analyze_maintenance_needs(self, sensor_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì •ë¹„ í•„ìš”ì„± ë¶„ì„"""
        # êµ¬í˜„ ì˜ˆì •
        return {}
    
    async def extract_tire_specific_data(self, sensor_data: List[Dict[str, Any]], tire_index: int) -> List[Dict[str, Any]]:
        """íŠ¹ì • íƒ€ì´ì–´ ë°ì´í„° ì¶”ì¶œ"""
        # êµ¬í˜„ ì˜ˆì •
        return sensor_data
    
    async def predict_tire_maintenance(self, tire_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ê°œë³„ íƒ€ì´ì–´ ì •ë¹„ ì˜ˆì¸¡"""
        # êµ¬í˜„ ì˜ˆì •
        return {"days_remaining": 90, "confidence": 0.8}
    
    async def predict_system_maintenance(self, sensor_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì‹œìŠ¤í…œ ì „ì²´ ì •ë¹„ ì˜ˆì¸¡"""
        # êµ¬í˜„ ì˜ˆì •
        return {"next_maintenance": "2025-02-15", "type": "ì •ê¸°ì ê²€"}
    
    async def calculate_maintenance_priority(self, tire_maintenance: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ì •ë¹„ ìš°ì„ ìˆœìœ„ ê³„ì‚°"""
        # êµ¬í˜„ ì˜ˆì •
        return [{"tire": "tire_1", "priority": "high", "reason": "ì••ë ¥ ì €í•˜"}]
    
    async def estimate_maintenance_cost(self, tire_maintenance: Dict[str, Any], system_maintenance: Dict[str, Any]) -> Dict[str, float]:
        """ì •ë¹„ ë¹„ìš© ì¶”ì •"""
        # êµ¬í˜„ ì˜ˆì •
        return {"tire_cost": 50000, "system_cost": 100000, "total": 150000}
    
    async def recommend_maintenance_date(self, tire_maintenance: Dict[str, Any]) -> str:
        """ì •ë¹„ ê¶Œì¥ ë‚ ì§œ"""
        # êµ¬í˜„ ì˜ˆì •
        return (datetime.now() + timedelta(days=30)).strftime("%Y-%m-%d")