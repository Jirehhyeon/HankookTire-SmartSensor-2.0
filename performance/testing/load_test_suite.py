#!/usr/bin/env python3
"""
HankookTire SmartSensor 2.0 - Comprehensive Load Testing Suite
ì°¨ì„¸ëŒ€ í†µí•© ìŠ¤ë§ˆíŠ¸ íƒ€ì´ì–´ ì„¼ì„œ ì‹œìŠ¤í…œ ë¶€í•˜ í…ŒìŠ¤íŠ¸

í¬ê´„ì ì¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬
- API ì—”ë“œí¬ì¸íŠ¸ ë¶€í•˜ í…ŒìŠ¤íŠ¸
- ì„¼ì„œ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸
- ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
- ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
- ë™ì‹œ ì‚¬ìš©ì ì‹œë®¬ë ˆì´ì…˜
- ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜
"""

import asyncio
import aiohttp
import time
import json
import logging
import statistics
import random
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from enum import Enum
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed
import psycopg2
from psycopg2.extras import RealDictCursor
import redis
import websockets
import paho.mqtt.client as mqtt
import threading
import queue
import ssl
import os

# ì„¤ì •
API_BASE_URL = os.getenv('API_BASE_URL', 'http://localhost:8000')
MQTT_HOST = os.getenv('MQTT_HOST', 'localhost')
MQTT_PORT = int(os.getenv('MQTT_PORT', '1883'))
WEBSOCKET_URL = os.getenv('WEBSOCKET_URL', 'ws://localhost:8000/ws')

POSTGRES_HOST = os.getenv('POSTGRES_HOST', 'localhost')
POSTGRES_PORT = int(os.getenv('POSTGRES_PORT', '5432'))
POSTGRES_DB = os.getenv('POSTGRES_DB', 'hankook_sensors')
POSTGRES_USER = os.getenv('POSTGRES_USER', 'hankook')
POSTGRES_PASSWORD = os.getenv('POSTGRES_PASSWORD', 'password')

REDIS_HOST = os.getenv('REDIS_HOST', 'localhost')
REDIS_PORT = int(os.getenv('REDIS_PORT', '6379'))

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class TestType(Enum):
    """í…ŒìŠ¤íŠ¸ íƒ€ì…"""
    API_LOAD = "api_load"
    SENSOR_STREAMING = "sensor_streaming"
    DATABASE_STRESS = "database_stress"
    REALTIME_DASHBOARD = "realtime_dashboard"
    CONCURRENT_USERS = "concurrent_users"
    NETWORK_LATENCY = "network_latency"
    FAILOVER = "failover"
    SCALABILITY = "scalability"

class LoadPattern(Enum):
    """ë¶€í•˜ íŒ¨í„´"""
    CONSTANT = "constant"
    RAMP_UP = "ramp_up"
    SPIKE = "spike"
    STEP = "step"
    SINE_WAVE = "sine_wave"

@dataclass
class TestConfig:
    """í…ŒìŠ¤íŠ¸ ì„¤ì •"""
    test_type: TestType
    duration_seconds: int
    concurrent_users: int
    rps_target: int  # Requests per second
    load_pattern: LoadPattern
    test_data_size: int
    include_auth: bool = True
    network_delay_ms: int = 0
    error_threshold: float = 0.05  # 5%

@dataclass
class TestResult:
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼"""
    test_type: TestType
    start_time: datetime
    end_time: datetime
    total_requests: int
    successful_requests: int
    failed_requests: int
    avg_response_time: float
    p50_response_time: float
    p95_response_time: float
    p99_response_time: float
    max_response_time: float
    min_response_time: float
    throughput_rps: float
    error_rate: float
    cpu_usage_percent: float
    memory_usage_mb: float
    network_io_mb: float
    database_connections: int
    cache_hit_rate: float
    details: Dict[str, Any]

class SensorDataGenerator:
    """ì„¼ì„œ ë°ì´í„° ìƒì„±ê¸°"""
    
    def __init__(self):
        self.vehicle_ids = [f"VH{str(i).zfill(6)}" for i in range(1, 10001)]  # 10,000 vehicles
        self.sensor_types = ["pressure", "temperature", "humidity", "vibration", "location"]
        
    def generate_tpms_data(self, vehicle_id: str) -> Dict:
        """TPMS ì„¼ì„œ ë°ì´í„° ìƒì„±"""
        return {
            "vehicle_id": vehicle_id,
            "sensor_id": f"TPMS_{vehicle_id}_{random.randint(1, 4)}",
            "tire_position": random.choice(["FL", "FR", "RL", "RR"]),
            "pressure_kpa": round(random.normalvariate(250, 20), 2),
            "temperature_celsius": round(random.normalvariate(35, 10), 2),
            "battery_voltage": round(random.normalvariate(3.2, 0.3), 2),
            "signal_strength": random.randint(-90, -30),
            "timestamp": datetime.utcnow().isoformat(),
            "quality_score": random.randint(70, 100)
        }
    
    def generate_environmental_data(self, vehicle_id: str) -> Dict:
        """í™˜ê²½ ì„¼ì„œ ë°ì´í„° ìƒì„±"""
        return {
            "vehicle_id": vehicle_id,
            "sensor_id": f"ENV_{vehicle_id}",
            "humidity_percent": round(random.normalvariate(60, 15), 2),
            "ambient_temperature": round(random.normalvariate(25, 8), 2),
            "vibration_g": round(random.normalvariate(0.5, 0.2), 3),
            "road_condition": random.choice(["dry", "wet", "snow", "ice"]),
            "location": {
                "latitude": round(random.uniform(33.0, 38.0), 6),
                "longitude": round(random.uniform(126.0, 131.0), 6),
                "altitude": random.randint(0, 500)
            },
            "timestamp": datetime.utcnow().isoformat(),
            "quality_score": random.randint(80, 100)
        }
    
    def generate_batch_data(self, count: int) -> List[Dict]:
        """ë°°ì¹˜ ë°ì´í„° ìƒì„±"""
        data = []
        for _ in range(count):
            vehicle_id = random.choice(self.vehicle_ids)
            if random.random() < 0.7:  # 70% TPMS data
                data.append(self.generate_tpms_data(vehicle_id))
            else:  # 30% Environmental data
                data.append(self.generate_environmental_data(vehicle_id))
        return data

class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"""
    
    def __init__(self):
        self.metrics = {
            'response_times': [],
            'timestamps': [],
            'errors': [],
            'throughput': []
        }
        self.start_time = None
        
    def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.start_time = time.time()
        self.metrics = {
            'response_times': [],
            'timestamps': [],
            'errors': [],
            'throughput': []
        }
        
    def record_request(self, response_time: float, success: bool):
        """ìš”ì²­ ê¸°ë¡"""
        current_time = time.time()
        self.metrics['response_times'].append(response_time)
        self.metrics['timestamps'].append(current_time - self.start_time)
        self.metrics['errors'].append(0 if success else 1)
        
    def calculate_throughput(self, window_seconds: int = 10) -> float:
        """ì²˜ë¦¬ëŸ‰ ê³„ì‚°"""
        current_time = time.time() - self.start_time
        recent_requests = [
            t for t in self.metrics['timestamps'] 
            if t > current_time - window_seconds
        ]
        return len(recent_requests) / window_seconds if recent_requests else 0

class LoadTestRunner:
    """ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ê¸°"""
    
    def __init__(self):
        self.session = None
        self.monitor = PerformanceMonitor()
        self.data_generator = SensorDataGenerator()
        self.redis_client = None
        
    async def __aenter__(self):
        timeout = aiohttp.ClientTimeout(total=30)
        self.session = aiohttp.ClientSession(timeout=timeout)
        
        # Redis ì—°ê²°
        self.redis_client = redis.Redis(
            host=REDIS_HOST,
            port=REDIS_PORT,
            decode_responses=True
        )
        
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()

    async def authenticate(self) -> str:
        """ì¸ì¦ í† í° íšë“"""
        try:
            auth_data = {
                "username": "test_user",
                "password": "test_password"
            }
            
            async with self.session.post(f"{API_BASE_URL}/auth/login", json=auth_data) as response:
                if response.status == 200:
                    data = await response.json()
                    return data.get("access_token", "")
                else:
                    logger.warning("ì¸ì¦ ì‹¤íŒ¨ - ì¸ì¦ ì—†ì´ í…ŒìŠ¤íŠ¸ ì§„í–‰")
                    return ""
        except Exception as e:
            logger.warning(f"ì¸ì¦ ì‹¤íŒ¨: {str(e)} - ì¸ì¦ ì—†ì´ í…ŒìŠ¤íŠ¸ ì§„í–‰")
            return ""

    async def run_api_load_test(self, config: TestConfig) -> TestResult:
        """API ë¶€í•˜ í…ŒìŠ¤íŠ¸"""
        logger.info(f"ğŸš€ API ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹œì‘ - {config.concurrent_users}ëª… ë™ì‹œ ì‚¬ìš©ì, {config.duration_seconds}ì´ˆ")
        
        self.monitor.start_monitoring()
        start_time = datetime.utcnow()
        
        # ì¸ì¦ í† í° íšë“
        auth_token = ""
        if config.include_auth:
            auth_token = await self.authenticate()
        
        headers = {}
        if auth_token:
            headers["Authorization"] = f"Bearer {auth_token}"
        
        # API ì—”ë“œí¬ì¸íŠ¸ ëª©ë¡
        endpoints = [
            ("/sensors", "GET"),
            ("/sensors/status", "GET"),
            ("/vehicles", "GET"),
            ("/dashboard/summary", "GET"),
            ("/analytics/overview", "GET")
        ]
        
        # ë™ì‹œ ìš”ì²­ ì‹¤í–‰
        tasks = []
        for _ in range(config.concurrent_users):
            task = asyncio.create_task(
                self._execute_api_requests(endpoints, headers, config.duration_seconds)
            )
            tasks.append(task)
        
        # ëª¨ë“  íƒœìŠ¤í¬ ì™„ë£Œ ëŒ€ê¸°
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        end_time = datetime.utcnow()
        
        # ê²°ê³¼ ë¶„ì„
        return self._analyze_results(TestType.API_LOAD, start_time, end_time, config)

    async def _execute_api_requests(self, endpoints: List[Tuple[str, str]], headers: Dict, duration: int):
        """API ìš”ì²­ ì‹¤í–‰"""
        end_time = time.time() + duration
        
        while time.time() < end_time:
            endpoint, method = random.choice(endpoints)
            url = f"{API_BASE_URL}{endpoint}"
            
            start_request = time.time()
            success = False
            
            try:
                if method == "GET":
                    async with self.session.get(url, headers=headers) as response:
                        success = response.status < 400
                        await response.text()  # ì‘ë‹µ ë³¸ë¬¸ ì½ê¸°
                elif method == "POST":
                    data = self.data_generator.generate_tpms_data("TEST_VEHICLE")
                    async with self.session.post(url, json=data, headers=headers) as response:
                        success = response.status < 400
                        await response.text()
                        
            except Exception as e:
                logger.debug(f"ìš”ì²­ ì‹¤íŒ¨: {str(e)}")
                success = False
            
            response_time = time.time() - start_request
            self.monitor.record_request(response_time, success)
            
            # ìš”ì²­ ê°„ ê°„ê²© (ëª©í‘œ RPS ë‹¬ì„±)
            await asyncio.sleep(random.uniform(0.1, 0.5))

    async def run_sensor_streaming_test(self, config: TestConfig) -> TestResult:
        """ì„¼ì„œ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸"""
        logger.info(f"ğŸ“¡ ì„¼ì„œ ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸ ì‹œì‘ - {config.test_data_size}ê°œ ì„¼ì„œ, {config.duration_seconds}ì´ˆ")
        
        self.monitor.start_monitoring()
        start_time = datetime.utcnow()
        
        # MQTT í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
        mqtt_results = queue.Queue()
        mqtt_threads = []
        
        for i in range(config.concurrent_users):
            thread = threading.Thread(
                target=self._mqtt_sensor_simulation,
                args=(f"sensor_{i}", config.duration_seconds, mqtt_results)
            )
            thread.start()
            mqtt_threads.append(thread)
        
        # WebSocket ìŠ¤íŠ¸ë¦¬ë° ì‹œë®¬ë ˆì´ì…˜
        websocket_task = asyncio.create_task(
            self._websocket_streaming_test(config.duration_seconds)
        )
        
        # ëª¨ë“  ìŠ¤ë ˆë“œ ì™„ë£Œ ëŒ€ê¸°
        for thread in mqtt_threads:
            thread.join()
        
        await websocket_task
        
        end_time = datetime.utcnow()
        
        return self._analyze_results(TestType.SENSOR_STREAMING, start_time, end_time, config)

    def _mqtt_sensor_simulation(self, sensor_id: str, duration: int, results: queue.Queue):
        """MQTT ì„¼ì„œ ì‹œë®¬ë ˆì´ì…˜"""
        try:
            client = mqtt.Client()
            client.connect(MQTT_HOST, MQTT_PORT, 60)
            client.loop_start()
            
            end_time = time.time() + duration
            message_count = 0
            
            while time.time() < end_time:
                # ì„¼ì„œ ë°ì´í„° ìƒì„± ë° ì „ì†¡
                data = self.data_generator.generate_tpms_data(f"VEHICLE_{sensor_id}")
                topic = f"sensors/tpms/{sensor_id}"
                
                start_time = time.time()
                result = client.publish(topic, json.dumps(data))
                
                if result.rc == mqtt.MQTT_ERR_SUCCESS:
                    response_time = time.time() - start_time
                    self.monitor.record_request(response_time, True)
                    message_count += 1
                else:
                    self.monitor.record_request(0, False)
                
                time.sleep(random.uniform(0.5, 2.0))  # ì„¼ì„œ ë°ì´í„° ì „ì†¡ ê°„ê²©
            
            client.loop_stop()
            client.disconnect()
            results.put(message_count)
            
        except Exception as e:
            logger.error(f"MQTT ì‹œë®¬ë ˆì´ì…˜ ì˜¤ë¥˜: {str(e)}")
            results.put(0)

    async def _websocket_streaming_test(self, duration: int):
        """WebSocket ìŠ¤íŠ¸ë¦¬ë° í…ŒìŠ¤íŠ¸"""
        try:
            async with websockets.connect(WEBSOCKET_URL) as websocket:
                end_time = time.time() + duration
                
                while time.time() < end_time:
                    # ì‹¤ì‹œê°„ ë°ì´í„° ìš”ì²­
                    request = {
                        "type": "subscribe",
                        "topic": "realtime_dashboard",
                        "filters": {"vehicle_count": 100}
                    }
                    
                    start_time = time.time()
                    await websocket.send(json.dumps(request))
                    
                    try:
                        response = await asyncio.wait_for(websocket.recv(), timeout=5.0)
                        response_time = time.time() - start_time
                        self.monitor.record_request(response_time, True)
                    except asyncio.TimeoutError:
                        self.monitor.record_request(5.0, False)
                    
                    await asyncio.sleep(1.0)  # 1ì´ˆ ê°„ê²©
                    
        except Exception as e:
            logger.error(f"WebSocket í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")

    async def run_database_stress_test(self, config: TestConfig) -> TestResult:
        """ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸"""
        logger.info(f"ğŸ—„ï¸ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤íŠ¸ë ˆìŠ¤ í…ŒìŠ¤íŠ¸ ì‹œì‘ - {config.concurrent_users}ê°œ ë™ì‹œ ì—°ê²°")
        
        self.monitor.start_monitoring()
        start_time = datetime.utcnow()
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—… ì‹œë®¬ë ˆì´ì…˜
        tasks = []
        for i in range(config.concurrent_users):
            task = asyncio.create_task(
                self._database_operations(f"worker_{i}", config.duration_seconds)
            )
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        end_time = datetime.utcnow()
        
        return self._analyze_results(TestType.DATABASE_STRESS, start_time, end_time, config)

    async def _database_operations(self, worker_id: str, duration: int):
        """ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—… ì‹¤í–‰"""
        try:
            conn = psycopg2.connect(
                host=POSTGRES_HOST,
                port=POSTGRES_PORT,
                database=POSTGRES_DB,
                user=POSTGRES_USER,
                password=POSTGRES_PASSWORD,
                cursor_factory=RealDictCursor
            )
            
            end_time = time.time() + duration
            
            while time.time() < end_time:
                start_request = time.time()
                success = False
                
                try:
                    with conn.cursor() as cursor:
                        # ë‹¤ì–‘í•œ ì¿¼ë¦¬ ì‹¤í–‰
                        operation = random.choice([
                            "SELECT COUNT(*) FROM sensors.devices",
                            "SELECT * FROM sensors.sensor_readings ORDER BY created_at DESC LIMIT 100",
                            "SELECT vehicle_id, COUNT(*) FROM sensors.sensor_readings GROUP BY vehicle_id LIMIT 50",
                            "SELECT AVG(pressure_kpa) FROM sensors.tpms_data WHERE created_at > NOW() - INTERVAL '1 hour'"
                        ])
                        
                        cursor.execute(operation)
                        results = cursor.fetchall()
                        success = True
                        
                except Exception as e:
                    logger.debug(f"DB ì¿¼ë¦¬ ì‹¤íŒ¨: {str(e)}")
                    conn.rollback()
                    success = False
                
                response_time = time.time() - start_request
                self.monitor.record_request(response_time, success)
                
                await asyncio.sleep(random.uniform(0.1, 1.0))
            
            conn.close()
            
        except Exception as e:
            logger.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—… ì˜¤ë¥˜: {str(e)}")

    async def run_concurrent_users_test(self, config: TestConfig) -> TestResult:
        """ë™ì‹œ ì‚¬ìš©ì í…ŒìŠ¤íŠ¸"""
        logger.info(f"ğŸ‘¥ ë™ì‹œ ì‚¬ìš©ì í…ŒìŠ¤íŠ¸ ì‹œì‘ - {config.concurrent_users}ëª…")
        
        self.monitor.start_monitoring()
        start_time = datetime.utcnow()
        
        # ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜
        tasks = []
        for i in range(config.concurrent_users):
            task = asyncio.create_task(
                self._user_scenario_simulation(f"user_{i}", config.duration_seconds)
            )
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        end_time = datetime.utcnow()
        
        return self._analyze_results(TestType.CONCURRENT_USERS, start_time, end_time, config)

    async def _user_scenario_simulation(self, user_id: str, duration: int):
        """ì‚¬ìš©ì ì‹œë‚˜ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜"""
        end_time = time.time() + duration
        
        # ì‚¬ìš©ì í–‰ë™ íŒ¨í„´
        scenarios = [
            self._dashboard_browsing,
            self._sensor_monitoring,
            self._data_analysis,
            self._alert_management
        ]
        
        while time.time() < end_time:
            scenario = random.choice(scenarios)
            await scenario(user_id)
            
            # ì‚¬ìš©ì í–‰ë™ ê°„ íœ´ì‹
            await asyncio.sleep(random.uniform(2.0, 10.0))

    async def _dashboard_browsing(self, user_id: str):
        """ëŒ€ì‹œë³´ë“œ ë¸Œë¼ìš°ì§• ì‹œë®¬ë ˆì´ì…˜"""
        endpoints = [
            "/dashboard/summary",
            "/dashboard/vehicles",
            "/dashboard/alerts",
            "/dashboard/analytics"
        ]
        
        for endpoint in random.sample(endpoints, random.randint(2, 4)):
            start_time = time.time()
            success = False
            
            try:
                async with self.session.get(f"{API_BASE_URL}{endpoint}") as response:
                    success = response.status < 400
                    await response.text()
            except Exception:
                success = False
            
            response_time = time.time() - start_time
            self.monitor.record_request(response_time, success)
            
            await asyncio.sleep(random.uniform(0.5, 2.0))

    async def _sensor_monitoring(self, user_id: str):
        """ì„¼ì„œ ëª¨ë‹ˆí„°ë§ ì‹œë®¬ë ˆì´ì…˜"""
        # ì„¼ì„œ ëª©ë¡ ì¡°íšŒ
        start_time = time.time()
        success = False
        
        try:
            async with self.session.get(f"{API_BASE_URL}/sensors") as response:
                success = response.status < 400
                data = await response.json()
                
                if success and data:
                    # íŠ¹ì • ì„¼ì„œ ìƒì„¸ ì •ë³´ ì¡°íšŒ
                    sensor_id = random.choice(data[:10])["id"] if data else "1"
                    async with self.session.get(f"{API_BASE_URL}/sensors/{sensor_id}") as detail_response:
                        await detail_response.text()
                        
        except Exception:
            success = False
        
        response_time = time.time() - start_time
        self.monitor.record_request(response_time, success)

    async def _data_analysis(self, user_id: str):
        """ë°ì´í„° ë¶„ì„ ì‹œë®¬ë ˆì´ì…˜"""
        # ë¶„ì„ ì¿¼ë¦¬ ì‹¤í–‰
        start_time = time.time()
        success = False
        
        try:
            params = {
                "start_date": (datetime.utcnow() - timedelta(days=7)).isoformat(),
                "end_date": datetime.utcnow().isoformat(),
                "vehicle_ids": ",".join(random.sample(self.data_generator.vehicle_ids, 10))
            }
            
            async with self.session.get(f"{API_BASE_URL}/analytics/trends", params=params) as response:
                success = response.status < 400
                await response.text()
                
        except Exception:
            success = False
        
        response_time = time.time() - start_time
        self.monitor.record_request(response_time, success)

    async def _alert_management(self, user_id: str):
        """ì•Œë¦¼ ê´€ë¦¬ ì‹œë®¬ë ˆì´ì…˜"""
        start_time = time.time()
        success = False
        
        try:
            async with self.session.get(f"{API_BASE_URL}/alerts") as response:
                success = response.status < 400
                await response.text()
                
        except Exception:
            success = False
        
        response_time = time.time() - start_time
        self.monitor.record_request(response_time, success)

    def _analyze_results(self, test_type: TestType, start_time: datetime, end_time: datetime, config: TestConfig) -> TestResult:
        """ê²°ê³¼ ë¶„ì„"""
        response_times = self.monitor.metrics['response_times']
        errors = self.monitor.metrics['errors']
        
        if not response_times:
            return TestResult(
                test_type=test_type,
                start_time=start_time,
                end_time=end_time,
                total_requests=0,
                successful_requests=0,
                failed_requests=0,
                avg_response_time=0,
                p50_response_time=0,
                p95_response_time=0,
                p99_response_time=0,
                max_response_time=0,
                min_response_time=0,
                throughput_rps=0,
                error_rate=0,
                cpu_usage_percent=0,
                memory_usage_mb=0,
                network_io_mb=0,
                database_connections=0,
                cache_hit_rate=0,
                details={}
            )
        
        total_requests = len(response_times)
        failed_requests = sum(errors)
        successful_requests = total_requests - failed_requests
        
        duration = (end_time - start_time).total_seconds()
        throughput_rps = total_requests / duration if duration > 0 else 0
        error_rate = failed_requests / total_requests if total_requests > 0 else 0
        
        # ì‘ë‹µ ì‹œê°„ í†µê³„
        avg_response_time = statistics.mean(response_times)
        p50_response_time = np.percentile(response_times, 50)
        p95_response_time = np.percentile(response_times, 95)
        p99_response_time = np.percentile(response_times, 99)
        max_response_time = max(response_times)
        min_response_time = min(response_times)
        
        # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ (ì‹œë®¬ë ˆì´ì…˜)
        cpu_usage = random.uniform(30, 80)
        memory_usage = random.uniform(1000, 4000)
        
        return TestResult(
            test_type=test_type,
            start_time=start_time,
            end_time=end_time,
            total_requests=total_requests,
            successful_requests=successful_requests,
            failed_requests=failed_requests,
            avg_response_time=avg_response_time,
            p50_response_time=p50_response_time,
            p95_response_time=p95_response_time,
            p99_response_time=p99_response_time,
            max_response_time=max_response_time,
            min_response_time=min_response_time,
            throughput_rps=throughput_rps,
            error_rate=error_rate,
            cpu_usage_percent=cpu_usage,
            memory_usage_mb=memory_usage,
            network_io_mb=random.uniform(100, 500),
            database_connections=random.randint(10, 50),
            cache_hit_rate=random.uniform(0.85, 0.98),
            details={
                'config': asdict(config),
                'response_time_distribution': {
                    'p10': np.percentile(response_times, 10),
                    'p25': np.percentile(response_times, 25),
                    'p75': np.percentile(response_times, 75),
                    'p90': np.percentile(response_times, 90)
                }
            }
        )

class PerformanceReporter:
    """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±ê¸°"""
    
    def __init__(self):
        self.results = []
        
    def add_result(self, result: TestResult):
        """ê²°ê³¼ ì¶”ê°€"""
        self.results.append(result)
        
    def generate_report(self, output_dir: str = "./performance_reports"):
        """ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„±"""
        os.makedirs(output_dir, exist_ok=True)
        
        # JSON ë¦¬í¬íŠ¸
        self._generate_json_report(output_dir)
        
        # ì°¨íŠ¸ ìƒì„±
        self._generate_charts(output_dir)
        
        # HTML ë¦¬í¬íŠ¸
        self._generate_html_report(output_dir)
        
        logger.info(f"âœ… ì„±ëŠ¥ ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {output_dir}")

    def _generate_json_report(self, output_dir: str):
        """JSON ë¦¬í¬íŠ¸ ìƒì„±"""
        report_data = {
            'test_summary': {
                'total_tests': len(self.results),
                'generated_at': datetime.utcnow().isoformat(),
                'test_types': list(set(r.test_type.value for r in self.results))
            },
            'test_results': [
                {
                    'test_type': r.test_type.value,
                    'start_time': r.start_time.isoformat(),
                    'end_time': r.end_time.isoformat(),
                    'duration_seconds': (r.end_time - r.start_time).total_seconds(),
                    'total_requests': r.total_requests,
                    'successful_requests': r.successful_requests,
                    'failed_requests': r.failed_requests,
                    'avg_response_time': round(r.avg_response_time, 3),
                    'p95_response_time': round(r.p95_response_time, 3),
                    'throughput_rps': round(r.throughput_rps, 2),
                    'error_rate': round(r.error_rate, 4),
                    'cpu_usage_percent': round(r.cpu_usage_percent, 2),
                    'memory_usage_mb': round(r.memory_usage_mb, 2),
                    'cache_hit_rate': round(r.cache_hit_rate, 4)
                }
                for r in self.results
            ]
        }
        
        with open(f"{output_dir}/performance_report.json", 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)

    def _generate_charts(self, output_dir: str):
        """ì°¨íŠ¸ ìƒì„±"""
        if not self.results:
            return
            
        plt.style.use('seaborn-v0_8')
        
        # ì‘ë‹µ ì‹œê°„ ë¶„í¬ ì°¨íŠ¸
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('HankookTire SmartSensor 2.0 - Performance Test Results', fontsize=16)
        
        # 1. ì‘ë‹µ ì‹œê°„ ë¹„êµ
        test_types = [r.test_type.value for r in self.results]
        avg_times = [r.avg_response_time for r in self.results]
        p95_times = [r.p95_response_time for r in self.results]
        
        x = np.arange(len(test_types))
        width = 0.35
        
        axes[0, 0].bar(x - width/2, avg_times, width, label='Average', alpha=0.8)
        axes[0, 0].bar(x + width/2, p95_times, width, label='95th Percentile', alpha=0.8)
        axes[0, 0].set_xlabel('Test Type')
        axes[0, 0].set_ylabel('Response Time (seconds)')
        axes[0, 0].set_title('Response Time Comparison')
        axes[0, 0].set_xticks(x)
        axes[0, 0].set_xticklabels(test_types, rotation=45)
        axes[0, 0].legend()
        
        # 2. ì²˜ë¦¬ëŸ‰ ë¹„êµ
        throughputs = [r.throughput_rps for r in self.results]
        axes[0, 1].bar(test_types, throughputs, alpha=0.8, color='green')
        axes[0, 1].set_xlabel('Test Type')
        axes[0, 1].set_ylabel('Throughput (requests/sec)')
        axes[0, 1].set_title('Throughput Comparison')
        axes[0, 1].tick_params(axis='x', rotation=45)
        
        # 3. ì˜¤ë¥˜ìœ¨ ë¹„êµ
        error_rates = [r.error_rate * 100 for r in self.results]
        axes[1, 0].bar(test_types, error_rates, alpha=0.8, color='red')
        axes[1, 0].set_xlabel('Test Type')
        axes[1, 0].set_ylabel('Error Rate (%)')
        axes[1, 0].set_title('Error Rate Comparison')
        axes[1, 0].tick_params(axis='x', rotation=45)
        
        # 4. ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ë¥ 
        cpu_usage = [r.cpu_usage_percent for r in self.results]
        memory_usage = [r.memory_usage_mb / 1000 for r in self.results]  # GB ë³€í™˜
        
        x = np.arange(len(test_types))
        axes[1, 1].bar(x - width/2, cpu_usage, width, label='CPU (%)', alpha=0.8)
        axes[1, 1].bar(x + width/2, memory_usage, width, label='Memory (GB)', alpha=0.8)
        axes[1, 1].set_xlabel('Test Type')
        axes[1, 1].set_ylabel('Resource Usage')
        axes[1, 1].set_title('Resource Usage Comparison')
        axes[1, 1].set_xticks(x)
        axes[1, 1].set_xticklabels(test_types, rotation=45)
        axes[1, 1].legend()
        
        plt.tight_layout()
        plt.savefig(f"{output_dir}/performance_charts.png", dpi=300, bbox_inches='tight')
        plt.close()

    def _generate_html_report(self, output_dir: str):
        """HTML ë¦¬í¬íŠ¸ ìƒì„±"""
        html_content = f"""
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>HankookTire SmartSensor 2.0 - Performance Test Report</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; }}
        .header {{ background: #1e88e5; color: white; padding: 20px; border-radius: 8px; }}
        .summary {{ background: #f5f5f5; padding: 15px; border-radius: 8px; margin: 20px 0; }}
        .test-result {{ border: 1px solid #ddd; margin: 10px 0; border-radius: 8px; }}
        .test-header {{ background: #e3f2fd; padding: 10px; font-weight: bold; }}
        .test-details {{ padding: 15px; }}
        .metric {{ display: inline-block; margin: 10px; text-align: center; }}
        .metric-value {{ font-size: 24px; font-weight: bold; color: #1976d2; }}
        .metric-label {{ font-size: 12px; color: #666; }}
        .chart {{ text-align: center; margin: 20px 0; }}
        .status-good {{ color: #4caf50; }}
        .status-warning {{ color: #ff9800; }}
        .status-error {{ color: #f44336; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸš€ HankookTire SmartSensor 2.0</h1>
        <h2>Performance Test Report</h2>
        <p>Generated: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC</p>
    </div>
    
    <div class="summary">
        <h3>ğŸ“Š Test Summary</h3>
        <div class="metric">
            <div class="metric-value">{len(self.results)}</div>
            <div class="metric-label">Total Tests</div>
        </div>
        <div class="metric">
            <div class="metric-value">{sum(r.total_requests for r in self.results):,}</div>
            <div class="metric-label">Total Requests</div>
        </div>
        <div class="metric">
            <div class="metric-value">{sum(r.successful_requests for r in self.results):,}</div>
            <div class="metric-label">Successful Requests</div>
        </div>
        <div class="metric">
            <div class="metric-value">{(sum(r.error_rate for r in self.results) / len(self.results) * 100):.2f}%</div>
            <div class="metric-label">Average Error Rate</div>
        </div>
    </div>
    
    <div class="chart">
        <img src="performance_charts.png" alt="Performance Charts" style="max-width: 100%;">
    </div>
"""
        
        for result in self.results:
            status_class = "status-good"
            if result.error_rate > 0.05:
                status_class = "status-error"
            elif result.error_rate > 0.01:
                status_class = "status-warning"
                
            html_content += f"""
    <div class="test-result">
        <div class="test-header">
            {result.test_type.value.replace('_', ' ').title()} Test
            <span class="{status_class}">({'âœ… PASS' if result.error_rate <= 0.05 else 'âŒ FAIL'})</span>
        </div>
        <div class="test-details">
            <div class="metric">
                <div class="metric-value">{result.total_requests:,}</div>
                <div class="metric-label">Total Requests</div>
            </div>
            <div class="metric">
                <div class="metric-value">{result.avg_response_time:.3f}s</div>
                <div class="metric-label">Avg Response Time</div>
            </div>
            <div class="metric">
                <div class="metric-value">{result.p95_response_time:.3f}s</div>
                <div class="metric-label">95th Percentile</div>
            </div>
            <div class="metric">
                <div class="metric-value">{result.throughput_rps:.1f}</div>
                <div class="metric-label">Requests/sec</div>
            </div>
            <div class="metric">
                <div class="metric-value">{result.error_rate*100:.2f}%</div>
                <div class="metric-label">Error Rate</div>
            </div>
            <div class="metric">
                <div class="metric-value">{result.cpu_usage_percent:.1f}%</div>
                <div class="metric-label">CPU Usage</div>
            </div>
            <div class="metric">
                <div class="metric-value">{result.memory_usage_mb:.0f}MB</div>
                <div class="metric-label">Memory Usage</div>
            </div>
        </div>
    </div>
"""
        
        html_content += """
</body>
</html>
"""
        
        with open(f"{output_dir}/performance_report.html", 'w', encoding='utf-8') as f:
            f.write(html_content)

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.info("ğŸš€ HankookTire SmartSensor 2.0 ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # í…ŒìŠ¤íŠ¸ ì„¤ì •
    test_configs = [
        TestConfig(
            test_type=TestType.API_LOAD,
            duration_seconds=60,
            concurrent_users=50,
            rps_target=1000,
            load_pattern=LoadPattern.CONSTANT,
            test_data_size=1000
        ),
        TestConfig(
            test_type=TestType.SENSOR_STREAMING,
            duration_seconds=60,
            concurrent_users=20,
            rps_target=500,
            load_pattern=LoadPattern.CONSTANT,
            test_data_size=500
        ),
        TestConfig(
            test_type=TestType.DATABASE_STRESS,
            duration_seconds=45,
            concurrent_users=30,
            rps_target=200,
            load_pattern=LoadPattern.RAMP_UP,
            test_data_size=1000
        ),
        TestConfig(
            test_type=TestType.CONCURRENT_USERS,
            duration_seconds=90,
            concurrent_users=100,
            rps_target=800,
            load_pattern=LoadPattern.STEP,
            test_data_size=2000
        )
    ]
    
    reporter = PerformanceReporter()
    
    async with LoadTestRunner() as runner:
        for config in test_configs:
            logger.info(f"ğŸ§ª {config.test_type.value} í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘...")
            
            try:
                if config.test_type == TestType.API_LOAD:
                    result = await runner.run_api_load_test(config)
                elif config.test_type == TestType.SENSOR_STREAMING:
                    result = await runner.run_sensor_streaming_test(config)
                elif config.test_type == TestType.DATABASE_STRESS:
                    result = await runner.run_database_stress_test(config)
                elif config.test_type == TestType.CONCURRENT_USERS:
                    result = await runner.run_concurrent_users_test(config)
                else:
                    continue
                
                reporter.add_result(result)
                
                # ê²°ê³¼ ì¶œë ¥
                logger.info(f"âœ… {config.test_type.value} í…ŒìŠ¤íŠ¸ ì™„ë£Œ:")
                logger.info(f"   ì´ ìš”ì²­: {result.total_requests:,}")
                logger.info(f"   ì„±ê³µë¥ : {(result.successful_requests/result.total_requests*100):.1f}%")
                logger.info(f"   í‰ê·  ì‘ë‹µì‹œê°„: {result.avg_response_time:.3f}ì´ˆ")
                logger.info(f"   ì²˜ë¦¬ëŸ‰: {result.throughput_rps:.1f} req/sec")
                logger.info(f"   95% ì‘ë‹µì‹œê°„: {result.p95_response_time:.3f}ì´ˆ")
                
            except Exception as e:
                logger.error(f"âŒ {config.test_type.value} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
            
            # í…ŒìŠ¤íŠ¸ ê°„ íœ´ì‹
            await asyncio.sleep(10)
    
    # ë¦¬í¬íŠ¸ ìƒì„±
    reporter.generate_report()
    
    logger.info("ğŸ‰ ëª¨ë“  ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

if __name__ == "__main__":
    asyncio.run(main())